{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, SAGEConv, global_add_pool, global_mean_pool\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "MOFname                                          0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "CO2_working_capacity [mL/g]                      0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(68611, 26)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/clean_train.csv')\n",
    "smiles = pd.read_csv('data/train/smiles_train.csv')\n",
    "mol2vec = pickle.load(open('data/train/mol2vec.pkl', 'rb'))\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "mask = ~data['Smiles'].isnull().values\n",
    "mol2vec = mol2vec[mask]\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e11f0e34-b17a-4f43-9a1a-0b4f0d2fc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = {\n",
    "    'atomic_num':\n",
    "    list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED',\n",
    "        'CHI_TETRAHEDRAL_CW',\n",
    "        'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER',\n",
    "    ],\n",
    "    'degree':\n",
    "    list(range(0, 11)),\n",
    "    'formal_charge':\n",
    "    list(range(-5, 7)),\n",
    "    'num_hs':\n",
    "    list(range(0, 9)),\n",
    "    'num_radical_electrons':\n",
    "    list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED',\n",
    "        'S',\n",
    "        'SP',\n",
    "        'SP2',\n",
    "        'SP3',\n",
    "        'SP3D',\n",
    "        'SP3D2',\n",
    "        'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "}\n",
    "\n",
    "e_map = {\n",
    "    'bond_type': [\n",
    "        'misc',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'AROMATIC',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "        'STEREOANY',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n",
      "done: 20000\n",
      "done: 30000\n",
      "done: 40000\n",
      "done: 50000\n",
      "done: 60000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "c = 1\n",
    "for idx, line in data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(line['Smiles'])\n",
    "    \n",
    "    if mol == None:\n",
    "        continue\n",
    "    \n",
    "    # Create Node Features\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        x.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        x.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        x.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        x.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        x.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        x.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        x.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        x.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        xs.append(x)\n",
    "    x = torch.tensor(xs, dtype=torch.float).view(-1, 9)\n",
    "    \n",
    "    # Create Edge Features\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    # Sort indices.\n",
    "    if edge_index.numel() > 0:\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    x_feat = line.drop(['MOFname', 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]', 'Smiles']).values.astype(float) #, 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]'\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "    \n",
    "    vec = np.expand_dims(mol2vec[idx], axis=0)\n",
    "    vec = torch.tensor(vec)\n",
    "    \n",
    "    x_feat = torch.cat((x_feat, vec), dim=1)\n",
    "    \n",
    "    y=torch.tensor([line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    \n",
    "    data_d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=line['Smiles'], mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "    data_d.num_nodes = len(mol.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_vec.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 55125\n",
      "Number of test graphs: 10500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.16, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "data_loader = DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.conv4 = SAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f8e2a6a-ba42-4c4a-8de0-bf276fd3976b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.gine = GINE(in_xs, in_attr, dim, 128)\n",
    "        self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "        self.bn = BatchNorm1d(256)\n",
    "        self.lin = Sequential(Linear(256, 128), BatchNorm1d(128))\n",
    "        self.lin2 = Sequential(Linear(128, 128), BatchNorm1d(128))\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(128)\n",
    "        self.mlp_cross = MLP(128, 256, 128)\n",
    "        \n",
    "        self.bn_cat = BatchNorm1d(256)\n",
    "        self.mlp_cat = MLP(256, 256, 128)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(128, out_channels) # 256\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, x_feat):\n",
    "        x = self.gine(x, edge_index, edge_attr, batch)\n",
    "        x_feat = self.mlp_num(x_feat)\n",
    "        concat = torch.cat((x, x_feat),dim=1)\n",
    "        x = self.bn(concat)\n",
    "        x = self.lin(x)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "        xl = self.crossnet(x)\n",
    "        x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn_cat(x)\n",
    "        x = self.mlp_cat(x)\n",
    "        x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00365a0-505e-4adf-b703-f17774e8e674",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.gin = GCN(in_xs, dim, 128)\n",
    "        self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "        self.bn = BatchNorm1d(256)\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(256, layer_num=2)\n",
    "        self.mlp_cross = MLP(256, 256, 256)\n",
    "        \n",
    "        self.bn_cat = BatchNorm1d(256) #64+in_xfeats\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.gin(x, edge_index, batch)\n",
    "        x_feat = self.mlp_num(x_feat)\n",
    "        concat = torch.cat((x, x_feat),dim=1)\n",
    "        x = self.bn(concat)\n",
    "        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn_cat(hl)\n",
    "        x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a339c47-6c9b-408d-82ee-77e1efefdebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DCN, self).__init__()\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(in_channels)\n",
    "        self.mlp_cross = MLP(in_channels, 256, 128)\n",
    "        \n",
    "        self.bn = BatchNorm1d(128+in_channels)\n",
    "        self.mlp_cat = MLP(128+in_channels, 512, 256)\n",
    "        self.bn_out = BatchNorm1d(256)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "    def forward(self, x):        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "        xl = self.crossnet(x)\n",
    "        x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.mlp_cat(x)\n",
    "        x = self.bn_out(x)\n",
    "#         x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.g = SAGE(in_xs, dim, 32)\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(160, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.g(x, edge_index, batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        concat = torch.cat((x, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.45, training=self.training)\n",
    "#         x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.45, training=self.training)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        correct += loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 321\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 43.1645, Test MAE: 28.9799\n",
      "Epoch: 002, Train MAE: 29.7585, Test MAE: 27.4609\n",
      "Epoch: 003, Train MAE: 27.7953, Test MAE: 24.9166\n",
      "Epoch: 004, Train MAE: 26.6667, Test MAE: 23.8573\n",
      "Epoch: 005, Train MAE: 25.8521, Test MAE: 24.7507\n",
      "Epoch: 006, Train MAE: 25.2811, Test MAE: 26.7993\n",
      "Epoch: 007, Train MAE: 25.6200, Test MAE: 24.5208\n",
      "Epoch: 008, Train MAE: 24.8878, Test MAE: 24.2621\n",
      "Epoch: 009, Train MAE: 24.5576, Test MAE: 22.2441\n",
      "Epoch: 010, Train MAE: 24.1108, Test MAE: 21.7956\n",
      "Epoch: 011, Train MAE: 23.8442, Test MAE: 21.7565\n",
      "Epoch: 012, Train MAE: 23.8400, Test MAE: 22.7404\n",
      "Epoch: 013, Train MAE: 23.6072, Test MAE: 21.3739\n",
      "Epoch: 014, Train MAE: 23.3343, Test MAE: 22.2586\n",
      "Epoch: 015, Train MAE: 23.2439, Test MAE: 21.5691\n",
      "Epoch: 016, Train MAE: 23.3776, Test MAE: 21.1030\n",
      "Epoch: 017, Train MAE: 23.2465, Test MAE: 22.2006\n",
      "Epoch: 018, Train MAE: 22.9827, Test MAE: 21.1285\n",
      "Epoch: 019, Train MAE: 22.9257, Test MAE: 21.8906\n",
      "Epoch: 020, Train MAE: 22.9070, Test MAE: 21.1070\n",
      "Epoch: 021, Train MAE: 22.3670, Test MAE: 20.7132\n",
      "Epoch: 022, Train MAE: 22.4877, Test MAE: 20.3820\n",
      "Epoch: 023, Train MAE: 22.3557, Test MAE: 20.6783\n",
      "Epoch: 024, Train MAE: 22.4840, Test MAE: 21.5987\n",
      "Epoch: 025, Train MAE: 22.3778, Test MAE: 21.5674\n",
      "Epoch: 026, Train MAE: 22.1562, Test MAE: 20.7920\n",
      "Epoch: 027, Train MAE: 21.8086, Test MAE: 20.7898\n",
      "Epoch: 028, Train MAE: 21.7617, Test MAE: 20.5528\n",
      "Epoch: 029, Train MAE: 21.8116, Test MAE: 20.6364\n",
      "Epoch: 030, Train MAE: 21.8974, Test MAE: 21.1991\n",
      "Epoch: 031, Train MAE: 21.4722, Test MAE: 20.8810\n",
      "Epoch: 032, Train MAE: 21.4041, Test MAE: 20.6777\n",
      "Epoch: 033, Train MAE: 21.4712, Test MAE: 20.0020\n",
      "Epoch: 034, Train MAE: 21.2860, Test MAE: 20.2135\n",
      "Epoch: 035, Train MAE: 21.2775, Test MAE: 20.1172\n",
      "Epoch: 036, Train MAE: 21.2658, Test MAE: 20.4513\n",
      "Epoch: 037, Train MAE: 21.1892, Test MAE: 21.2116\n",
      "Epoch: 038, Train MAE: 21.1419, Test MAE: 19.8555\n",
      "Epoch: 039, Train MAE: 20.9807, Test MAE: 20.1186\n",
      "Epoch: 040, Train MAE: 20.9159, Test MAE: 20.0159\n",
      "Epoch: 041, Train MAE: 20.9675, Test MAE: 20.6153\n",
      "Epoch: 042, Train MAE: 20.9506, Test MAE: 20.0866\n",
      "Epoch: 043, Train MAE: 20.6898, Test MAE: 20.1749\n",
      "Epoch: 044, Train MAE: 20.6954, Test MAE: 19.8964\n",
      "Epoch: 045, Train MAE: 20.7225, Test MAE: 20.0588\n",
      "Epoch: 046, Train MAE: 20.6229, Test MAE: 20.1673\n",
      "Epoch: 047, Train MAE: 20.4878, Test MAE: 19.8842\n",
      "Epoch: 048, Train MAE: 20.4397, Test MAE: 20.1476\n",
      "Epoch: 049, Train MAE: 20.3965, Test MAE: 19.7412\n",
      "Epoch: 050, Train MAE: 20.4640, Test MAE: 19.9985\n",
      "Epoch: 051, Train MAE: 20.4409, Test MAE: 19.7044\n",
      "Epoch: 052, Train MAE: 20.3607, Test MAE: 20.1092\n",
      "Epoch: 053, Train MAE: 20.4110, Test MAE: 20.0055\n",
      "Epoch: 054, Train MAE: 20.2207, Test MAE: 19.6605\n",
      "Epoch: 055, Train MAE: 20.2879, Test MAE: 19.9973\n",
      "Epoch: 056, Train MAE: 20.3775, Test MAE: 20.5069\n",
      "Epoch: 057, Train MAE: 20.2726, Test MAE: 20.2913\n",
      "Epoch: 058, Train MAE: 20.2090, Test MAE: 20.0208\n",
      "Epoch: 059, Train MAE: 20.0853, Test MAE: 19.8880\n",
      "Epoch: 060, Train MAE: 20.2256, Test MAE: 19.6684\n",
      "Epoch: 061, Train MAE: 19.9944, Test MAE: 19.7603\n",
      "Epoch: 062, Train MAE: 20.0052, Test MAE: 19.7643\n",
      "Epoch: 063, Train MAE: 19.8573, Test MAE: 19.7836\n",
      "Epoch: 064, Train MAE: 19.8522, Test MAE: 20.0600\n",
      "Epoch: 065, Train MAE: 19.8470, Test MAE: 19.6169\n",
      "Epoch: 066, Train MAE: 19.7718, Test MAE: 19.7787\n",
      "Epoch: 067, Train MAE: 19.8289, Test MAE: 19.6744\n",
      "Epoch: 068, Train MAE: 19.7518, Test MAE: 19.7276\n",
      "Epoch: 069, Train MAE: 19.7916, Test MAE: 19.7541\n",
      "Epoch: 070, Train MAE: 19.6698, Test MAE: 19.7451\n",
      "Epoch: 071, Train MAE: 19.6348, Test MAE: 19.7771\n",
      "Epoch: 072, Train MAE: 19.6524, Test MAE: 19.8776\n",
      "Epoch: 073, Train MAE: 19.5819, Test MAE: 19.7061\n",
      "Epoch: 074, Train MAE: 19.5894, Test MAE: 19.9203\n",
      "Epoch: 075, Train MAE: 19.5069, Test MAE: 19.7148\n",
      "Epoch: 076, Train MAE: 19.5533, Test MAE: 19.8920\n",
      "Epoch: 077, Train MAE: 19.5390, Test MAE: 19.9818\n",
      "Epoch: 078, Train MAE: 19.4089, Test MAE: 19.8550\n",
      "Epoch: 079, Train MAE: 19.4765, Test MAE: 19.9847\n",
      "Epoch: 080, Train MAE: 19.3965, Test MAE: 19.7797\n",
      "Epoch: 081, Train MAE: 19.3973, Test MAE: 19.7146\n",
      "Epoch: 082, Train MAE: 19.2974, Test MAE: 19.6364\n",
      "Epoch: 083, Train MAE: 19.3374, Test MAE: 19.7380\n",
      "Epoch: 084, Train MAE: 19.3272, Test MAE: 19.6462\n",
      "Epoch: 085, Train MAE: 19.3483, Test MAE: 19.8273\n",
      "Epoch: 086, Train MAE: 19.1959, Test MAE: 19.6896\n",
      "Epoch: 087, Train MAE: 19.1741, Test MAE: 19.8733\n",
      "Epoch: 088, Train MAE: 19.1757, Test MAE: 19.7951\n",
      "Epoch: 089, Train MAE: 19.1134, Test MAE: 19.6310\n",
      "Epoch: 090, Train MAE: 19.2012, Test MAE: 19.7629\n",
      "Epoch: 091, Train MAE: 19.2176, Test MAE: 19.6699\n",
      "Epoch: 092, Train MAE: 19.0809, Test MAE: 19.7707\n",
      "Epoch: 093, Train MAE: 19.1020, Test MAE: 19.7221\n",
      "Epoch: 094, Train MAE: 19.0730, Test MAE: 19.6799\n",
      "Epoch: 095, Train MAE: 19.0790, Test MAE: 19.7209\n",
      "Epoch: 096, Train MAE: 19.0524, Test MAE: 19.7633\n",
      "Epoch: 097, Train MAE: 19.0571, Test MAE: 19.6623\n",
      "Epoch: 098, Train MAE: 18.9322, Test MAE: 19.6101\n",
      "Epoch: 099, Train MAE: 19.0169, Test MAE: 19.6886\n",
      "Epoch: 100, Train MAE: 18.9994, Test MAE: 19.7115\n",
      "Epoch: 101, Train MAE: 18.9964, Test MAE: 19.8513\n",
      "Epoch: 102, Train MAE: 18.9281, Test MAE: 19.7362\n",
      "Epoch: 103, Train MAE: 18.8756, Test MAE: 19.6791\n",
      "Epoch: 104, Train MAE: 18.9602, Test MAE: 19.6690\n",
      "Epoch: 105, Train MAE: 18.9421, Test MAE: 19.7394\n",
      "Epoch: 106, Train MAE: 18.9099, Test MAE: 19.7486\n",
      "Epoch: 107, Train MAE: 18.9026, Test MAE: 19.6891\n",
      "Epoch: 108, Train MAE: 18.8982, Test MAE: 19.6763\n",
      "Epoch: 109, Train MAE: 18.9141, Test MAE: 19.6749\n",
      "Epoch: 110, Train MAE: 18.8859, Test MAE: 19.7512\n",
      "Epoch: 111, Train MAE: 18.8586, Test MAE: 19.6641\n",
      "Epoch: 112, Train MAE: 18.7948, Test MAE: 19.7061\n",
      "Epoch: 113, Train MAE: 18.8527, Test MAE: 19.6649\n",
      "Epoch: 114, Train MAE: 18.7767, Test MAE: 19.6862\n",
      "Epoch: 115, Train MAE: 18.8021, Test MAE: 19.7220\n",
      "Epoch: 116, Train MAE: 18.7870, Test MAE: 19.7152\n",
      "Epoch: 117, Train MAE: 18.7914, Test MAE: 19.7037\n",
      "Epoch: 118, Train MAE: 18.7724, Test MAE: 19.8323\n",
      "Epoch: 119, Train MAE: 18.7495, Test MAE: 19.6986\n",
      "Epoch: 120, Train MAE: 18.7682, Test MAE: 19.6644\n",
      "Epoch: 121, Train MAE: 18.7254, Test MAE: 19.7103\n",
      "Epoch: 122, Train MAE: 18.7426, Test MAE: 19.6772\n",
      "Epoch: 123, Train MAE: 18.7538, Test MAE: 19.7002\n",
      "Epoch: 124, Train MAE: 18.6949, Test MAE: 19.7376\n",
      "Epoch: 125, Train MAE: 18.8309, Test MAE: 19.6835\n",
      "Epoch: 126, Train MAE: 18.7884, Test MAE: 19.6886\n",
      "Epoch: 127, Train MAE: 18.7137, Test MAE: 19.7310\n",
      "Epoch: 128, Train MAE: 18.6525, Test MAE: 19.7186\n",
      "Epoch: 129, Train MAE: 18.7832, Test MAE: 19.7042\n",
      "Epoch: 130, Train MAE: 18.7129, Test MAE: 19.6830\n",
      "Epoch: 131, Train MAE: 18.7061, Test MAE: 19.7084\n",
      "Epoch: 132, Train MAE: 18.7283, Test MAE: 19.7364\n",
      "Epoch: 133, Train MAE: 18.6440, Test MAE: 19.6911\n",
      "Epoch: 134, Train MAE: 18.6486, Test MAE: 19.7025\n",
      "Epoch: 135, Train MAE: 18.6380, Test MAE: 19.6793\n",
      "Epoch: 136, Train MAE: 18.7207, Test MAE: 19.7159\n",
      "Epoch: 137, Train MAE: 18.6568, Test MAE: 19.6689\n",
      "Epoch: 138, Train MAE: 18.7303, Test MAE: 19.7087\n",
      "Epoch: 139, Train MAE: 18.6522, Test MAE: 19.7094\n",
      "Epoch: 140, Train MAE: 18.6802, Test MAE: 19.7203\n",
      "Epoch: 141, Train MAE: 18.6409, Test MAE: 19.7217\n",
      "Epoch: 142, Train MAE: 18.7286, Test MAE: 19.7113\n",
      "Epoch: 143, Train MAE: 18.6868, Test MAE: 19.6899\n",
      "Epoch: 144, Train MAE: 18.5673, Test MAE: 19.7617\n",
      "Epoch: 145, Train MAE: 18.6073, Test MAE: 19.7185\n",
      "Epoch: 146, Train MAE: 18.6224, Test MAE: 19.7225\n",
      "Epoch: 147, Train MAE: 18.7362, Test MAE: 19.7025\n",
      "Epoch: 148, Train MAE: 18.6330, Test MAE: 19.6824\n",
      "Epoch: 149, Train MAE: 18.5606, Test MAE: 19.7076\n",
      "Epoch: 150, Train MAE: 18.6196, Test MAE: 19.6893\n",
      "Epoch: 151, Train MAE: 18.6449, Test MAE: 19.7012\n",
      "Epoch: 152, Train MAE: 18.6560, Test MAE: 19.6949\n",
      "Epoch: 153, Train MAE: 18.5754, Test MAE: 19.7113\n",
      "Epoch: 154, Train MAE: 18.6400, Test MAE: 19.7029\n",
      "Epoch: 155, Train MAE: 18.6405, Test MAE: 19.6937\n",
      "Epoch: 156, Train MAE: 18.5990, Test MAE: 19.7053\n",
      "Epoch: 157, Train MAE: 18.6381, Test MAE: 19.7027\n",
      "Epoch: 158, Train MAE: 18.5538, Test MAE: 19.6938\n",
      "Epoch: 159, Train MAE: 18.5956, Test MAE: 19.6832\n",
      "Epoch: 160, Train MAE: 18.6667, Test MAE: 19.7116\n",
      "Epoch: 161, Train MAE: 18.6070, Test MAE: 19.6867\n",
      "Epoch: 162, Train MAE: 18.6389, Test MAE: 19.6792\n",
      "Epoch: 163, Train MAE: 18.6227, Test MAE: 19.6863\n",
      "Epoch: 164, Train MAE: 18.6855, Test MAE: 19.6889\n",
      "Epoch: 165, Train MAE: 18.6396, Test MAE: 19.6943\n",
      "Epoch: 166, Train MAE: 18.6006, Test MAE: 19.7070\n",
      "Epoch: 167, Train MAE: 18.5640, Test MAE: 19.6748\n",
      "Epoch: 168, Train MAE: 18.6650, Test MAE: 19.6933\n",
      "Epoch: 169, Train MAE: 18.6290, Test MAE: 19.6935\n",
      "Epoch: 170, Train MAE: 18.5650, Test MAE: 19.6947\n",
      "Epoch: 171, Train MAE: 18.6422, Test MAE: 19.6900\n",
      "Epoch: 172, Train MAE: 18.6413, Test MAE: 19.6897\n",
      "Epoch: 173, Train MAE: 18.6690, Test MAE: 19.6977\n",
      "Epoch: 174, Train MAE: 18.6886, Test MAE: 19.6932\n",
      "Epoch: 175, Train MAE: 18.5067, Test MAE: 19.6898\n",
      "Epoch: 176, Train MAE: 18.6118, Test MAE: 19.6865\n",
      "Epoch: 177, Train MAE: 18.6391, Test MAE: 19.6857\n",
      "Epoch: 178, Train MAE: 18.5425, Test MAE: 19.6889\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15912/3879099282.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15912/2158525453.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Compute the loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Derive gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Update parameters based on gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Clear gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_numGNN2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65625\n",
      "Number of test graphs: 16237\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19612b6d-768d-47f0-be2d-b95967d97150",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "382f0082-062f-42cb-a1b4-4b22409384eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392a1c4-045e-4f56-9717-7c64816f1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out)\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>195.468613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>69.653137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>66.580437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>55.399101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>64.502907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-6.392035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.936134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>0.404633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-1.013318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-4.414718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   195.468613\n",
       "1      68615                    69.653137\n",
       "2      68616                    66.580437\n",
       "3      68617                    55.399101\n",
       "4      68618                    64.502907\n",
       "...      ...                          ...\n",
       "16995  85609                    -6.392035\n",
       "16996  85610                     1.936134\n",
       "16997  85611                     0.404633\n",
       "16998  85612                    -1.013318\n",
       "16999  85613                    -4.414718\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c6873-c420-4661-a9d2-aaf9dabfca55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

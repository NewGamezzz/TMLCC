{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, GraphConv, SAGEConv, ChebConv, global_add_pool, global_mean_pool\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "MOFname                                          0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "CO2_working_capacity [mL/g]                      0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(54072, 26)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/clean_train.csv')\n",
    "smiles = pd.read_csv('data/train/smiles_train.csv')\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "mask = data['surface_area [m^2/g]']>0\n",
    "mask = mask.values\n",
    "data = data[mask]\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e11f0e34-b17a-4f43-9a1a-0b4f0d2fc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = {\n",
    "    'atomic_num':\n",
    "    list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED',\n",
    "        'CHI_TETRAHEDRAL_CW',\n",
    "        'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER',\n",
    "    ],\n",
    "    'degree':\n",
    "    list(range(0, 11)),\n",
    "    'formal_charge':\n",
    "    list(range(-5, 7)),\n",
    "    'num_hs':\n",
    "    list(range(0, 9)),\n",
    "    'num_radical_electrons':\n",
    "    list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED',\n",
    "        'S',\n",
    "        'SP',\n",
    "        'SP2',\n",
    "        'SP3',\n",
    "        'SP3D',\n",
    "        'SP3D2',\n",
    "        'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "}\n",
    "\n",
    "e_map = {\n",
    "    'bond_type': [\n",
    "        'misc',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'AROMATIC',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "        'STEREOANY',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n",
      "done: 20000\n",
      "done: 30000\n",
      "done: 40000\n",
      "done: 50000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "c = 1\n",
    "for _, line in data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(line['Smiles'])\n",
    "    \n",
    "    if mol == None:\n",
    "        continue\n",
    "    \n",
    "    # Create Node Features\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        x.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        x.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        x.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        x.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        x.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        x.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        x.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        x.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        xs.append(x)\n",
    "    x = torch.tensor(xs, dtype=torch.float).view(-1, 9)\n",
    "    \n",
    "    # Create Edge Features\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    # Sort indices.\n",
    "    if edge_index.numel() > 0:\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    x_feat = line.drop(['MOFname', 'surface_area [m^2/g]', 'functional_groups', 'CO2_working_capacity [mL/g]', 'Smiles']).values.astype(float) #, 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]'\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "    y=torch.tensor([line['surface_area [m^2/g]']], dtype=torch.float).view(1, -1)\n",
    "    data_d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=line['Smiles'], mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "    data_d.num_nodes = len(mol.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_surface.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 41443\n",
      "Number of test graphs: 10361\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.2, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "data_loader = DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.conv4 = SAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ffba7f3-45e4-495d-a44d-8c9bd2fb90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(Graph, self).__init__()\n",
    "        self.conv1 = GraphConv(in_channels, dim)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.conv3 = GraphConv(dim, dim)\n",
    "        self.conv4 = GraphConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f8e2a6a-ba42-4c4a-8de0-bf276fd3976b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.gine = GINE(in_xs, in_attr, dim, 128)\n",
    "#         self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "#         self.bn = BatchNorm1d(256)\n",
    "#         self.lin = Sequential(Linear(256, 128), BatchNorm1d(128))\n",
    "#         self.lin2 = Sequential(Linear(128, 128), BatchNorm1d(128))\n",
    "#         # Deep & Cross Network\n",
    "#         self.crossnet = CrossNet(128)\n",
    "#         self.mlp_cross = MLP(128, 256, 128)\n",
    "        \n",
    "#         self.bn_cat = BatchNorm1d(256)\n",
    "#         self.mlp_cat = MLP(256, 256, 128)\n",
    "#         self.dropout = Dropout(p=0.5)\n",
    "#         self.out = Linear(128, out_channels) # 256\n",
    "\n",
    "#     def forward(self, x, edge_index, edge_attr, batch, x_feat):\n",
    "#         x = self.gine(x, edge_index, edge_attr, batch)\n",
    "#         x_feat = self.mlp_num(x_feat)\n",
    "#         concat = torch.cat((x, x_feat),dim=1)\n",
    "#         x = self.bn(concat)\n",
    "#         x = self.lin(x)\n",
    "#         x = self.lin2(x)\n",
    "        \n",
    "#         # Deep & Cross Network\n",
    "#         hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "#         x = self.bn_cat(x)\n",
    "#         x = self.mlp_cat(x)\n",
    "#         x = self.dropout(x)\n",
    "#         out = self.out(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00365a0-505e-4adf-b703-f17774e8e674",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.gin = GCN(in_xs, dim, 128)\n",
    "#         self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "#         self.bn = BatchNorm1d(256)\n",
    "#         # Deep & Cross Network\n",
    "#         self.crossnet = CrossNet(256, layer_num=2)\n",
    "#         self.mlp_cross = MLP(256, 256, 256)\n",
    "        \n",
    "#         self.bn_cat = BatchNorm1d(256) #64+in_xfeats\n",
    "#         self.dropout = Dropout(p=0.5)\n",
    "#         self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "#     def forward(self, x, edge_index, batch, x_feat):\n",
    "#         x = self.gin(x, edge_index, batch)\n",
    "#         x_feat = self.mlp_num(x_feat)\n",
    "#         concat = torch.cat((x, x_feat),dim=1)\n",
    "#         x = self.bn(concat)\n",
    "        \n",
    "#         # Deep & Cross Network\n",
    "#         hl = self.mlp_cross(x)\n",
    "# #         xl = self.crossnet(x)\n",
    "# #         x = torch.cat((xl, hl), dim=1)\n",
    "#         x = self.bn_cat(hl)\n",
    "#         x = self.dropout(x)\n",
    "#         out = self.out(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a339c47-6c9b-408d-82ee-77e1efefdebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class DCN(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DCN, self).__init__()\n",
    "#         # Deep & Cross Network\n",
    "#         self.crossnet = CrossNet(in_channels)\n",
    "#         self.mlp_cross = MLP(in_channels, 256, 128)\n",
    "        \n",
    "#         self.bn = BatchNorm1d(128+in_channels)\n",
    "#         self.mlp_cat = MLP(128+in_channels, 512, 256)\n",
    "#         self.bn_out = BatchNorm1d(256)\n",
    "#         self.dropout = Dropout(p=0.5)\n",
    "#         self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "#     def forward(self, x):        \n",
    "#         # Deep & Cross Network\n",
    "#         hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.mlp_cat(x)\n",
    "#         x = self.bn_out(x)\n",
    "# #         x = self.dropout(x)\n",
    "#         out = self.out(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.g = SAGE(in_xs, dim, 128) # SAGE\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(256, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.g(x, edge_index, batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        concat = torch.cat((x, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        correct += loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 128 # SAGE: 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001) #factor=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 548.8007, Test MAE: 181.6783\n",
      "Epoch: 002, Train MAE: 221.2975, Test MAE: 156.5692\n",
      "Epoch: 003, Train MAE: 214.0869, Test MAE: 241.5799\n",
      "Epoch: 004, Train MAE: 207.8136, Test MAE: 164.5903\n",
      "Epoch: 005, Train MAE: 199.2218, Test MAE: 159.3769\n",
      "Epoch: 006, Train MAE: 197.0280, Test MAE: 141.4553\n",
      "Epoch: 007, Train MAE: 191.6708, Test MAE: 147.9388\n",
      "Epoch: 008, Train MAE: 191.2291, Test MAE: 150.1068\n",
      "Epoch: 009, Train MAE: 186.2961, Test MAE: 155.4193\n",
      "Epoch: 010, Train MAE: 185.6123, Test MAE: 160.7253\n",
      "Epoch: 011, Train MAE: 185.3357, Test MAE: 137.2013\n",
      "Epoch: 012, Train MAE: 181.3685, Test MAE: 135.0738\n",
      "Epoch: 013, Train MAE: 181.2418, Test MAE: 162.3304\n",
      "Epoch: 014, Train MAE: 185.0928, Test MAE: 138.9326\n",
      "Epoch: 015, Train MAE: 181.1651, Test MAE: 145.0475\n",
      "Epoch: 016, Train MAE: 177.2984, Test MAE: 138.4613\n",
      "Epoch: 017, Train MAE: 175.3963, Test MAE: 131.2610\n",
      "Epoch: 018, Train MAE: 172.2570, Test MAE: 138.5842\n",
      "Epoch: 019, Train MAE: 173.5486, Test MAE: 145.5301\n",
      "Epoch: 020, Train MAE: 173.5706, Test MAE: 141.8140\n",
      "Epoch: 021, Train MAE: 174.9236, Test MAE: 149.1970\n",
      "Epoch: 022, Train MAE: 167.5196, Test MAE: 131.4149\n",
      "Epoch: 023, Train MAE: 168.2603, Test MAE: 137.6713\n",
      "Epoch: 024, Train MAE: 167.3094, Test MAE: 154.4270\n",
      "Epoch: 025, Train MAE: 167.9578, Test MAE: 148.4434\n",
      "Epoch: 026, Train MAE: 165.7220, Test MAE: 122.3127\n",
      "Epoch: 027, Train MAE: 164.3115, Test MAE: 132.0760\n",
      "Epoch: 028, Train MAE: 163.8324, Test MAE: 171.7072\n",
      "Epoch: 029, Train MAE: 163.7196, Test MAE: 146.8855\n",
      "Epoch: 030, Train MAE: 163.9704, Test MAE: 135.1192\n",
      "Epoch: 031, Train MAE: 162.7034, Test MAE: 137.2814\n",
      "Epoch: 032, Train MAE: 162.0194, Test MAE: 139.2314\n",
      "Epoch: 033, Train MAE: 160.9042, Test MAE: 123.3041\n",
      "Epoch: 034, Train MAE: 160.7383, Test MAE: 123.7651\n",
      "Epoch: 035, Train MAE: 158.8658, Test MAE: 115.9572\n",
      "Epoch: 036, Train MAE: 159.3874, Test MAE: 178.5332\n",
      "Epoch: 037, Train MAE: 158.8214, Test MAE: 153.9716\n",
      "Epoch: 038, Train MAE: 157.1612, Test MAE: 141.4688\n",
      "Epoch: 039, Train MAE: 157.8188, Test MAE: 122.7227\n",
      "Epoch: 040, Train MAE: 157.0254, Test MAE: 112.0752\n",
      "Epoch: 041, Train MAE: 156.0663, Test MAE: 166.7044\n",
      "Epoch: 042, Train MAE: 155.9443, Test MAE: 129.8891\n",
      "Epoch: 043, Train MAE: 155.5896, Test MAE: 135.8240\n",
      "Epoch: 044, Train MAE: 155.2225, Test MAE: 143.5601\n",
      "Epoch: 045, Train MAE: 154.1750, Test MAE: 137.4090\n",
      "Epoch: 046, Train MAE: 154.8039, Test MAE: 165.3738\n",
      "Epoch: 047, Train MAE: 152.7525, Test MAE: 140.0400\n",
      "Epoch: 048, Train MAE: 153.5180, Test MAE: 144.9759\n",
      "Epoch: 049, Train MAE: 153.2362, Test MAE: 140.6247\n",
      "Epoch: 050, Train MAE: 152.9483, Test MAE: 152.9749\n",
      "Epoch: 051, Train MAE: 153.9696, Test MAE: 132.8366\n",
      "Epoch: 052, Train MAE: 152.1715, Test MAE: 137.7539\n",
      "Epoch: 053, Train MAE: 151.5956, Test MAE: 145.8278\n",
      "Epoch: 054, Train MAE: 152.2998, Test MAE: 140.1894\n",
      "Epoch: 055, Train MAE: 152.4837, Test MAE: 138.6866\n",
      "Epoch: 056, Train MAE: 152.3321, Test MAE: 132.1490\n",
      "Epoch: 057, Train MAE: 150.1107, Test MAE: 154.4064\n",
      "Epoch: 058, Train MAE: 150.3188, Test MAE: 152.5642\n",
      "Epoch: 059, Train MAE: 149.4887, Test MAE: 141.8650\n",
      "Epoch: 060, Train MAE: 150.1073, Test MAE: 137.4359\n",
      "Epoch: 061, Train MAE: 149.1226, Test MAE: 141.0848\n",
      "Epoch: 062, Train MAE: 149.2084, Test MAE: 143.9831\n",
      "Epoch: 063, Train MAE: 148.3067, Test MAE: 160.0278\n",
      "Epoch: 064, Train MAE: 147.9298, Test MAE: 150.2527\n",
      "Epoch: 065, Train MAE: 148.5701, Test MAE: 167.0287\n",
      "Epoch: 066, Train MAE: 147.6136, Test MAE: 179.2728\n",
      "Epoch: 067, Train MAE: 147.8666, Test MAE: 169.9543\n",
      "Epoch: 068, Train MAE: 148.0122, Test MAE: 158.9732\n",
      "Epoch: 069, Train MAE: 148.0568, Test MAE: 161.8453\n",
      "Epoch: 070, Train MAE: 146.5845, Test MAE: 150.4104\n",
      "Epoch: 071, Train MAE: 147.4554, Test MAE: 131.9518\n",
      "Epoch: 072, Train MAE: 147.6629, Test MAE: 143.0307\n",
      "Epoch: 073, Train MAE: 147.7523, Test MAE: 143.7313\n",
      "Epoch: 074, Train MAE: 147.1399, Test MAE: 155.1168\n",
      "Epoch: 075, Train MAE: 146.8551, Test MAE: 142.4852\n",
      "Epoch: 076, Train MAE: 146.8764, Test MAE: 158.4726\n",
      "Epoch: 077, Train MAE: 145.9823, Test MAE: 152.8296\n",
      "Epoch: 078, Train MAE: 146.3542, Test MAE: 151.6896\n",
      "Epoch: 079, Train MAE: 145.4828, Test MAE: 159.0337\n",
      "Epoch: 080, Train MAE: 145.8665, Test MAE: 171.3691\n",
      "Epoch: 081, Train MAE: 146.2168, Test MAE: 152.6653\n",
      "Epoch: 082, Train MAE: 145.6526, Test MAE: 146.8487\n",
      "Epoch: 083, Train MAE: 145.9680, Test MAE: 142.3093\n",
      "Epoch: 084, Train MAE: 146.2640, Test MAE: 157.9977\n",
      "Epoch: 085, Train MAE: 145.7546, Test MAE: 153.4217\n",
      "Epoch: 086, Train MAE: 145.2565, Test MAE: 154.5056\n",
      "Epoch: 087, Train MAE: 145.4450, Test MAE: 165.3096\n",
      "Epoch: 088, Train MAE: 145.2205, Test MAE: 145.2911\n",
      "Epoch: 089, Train MAE: 145.0563, Test MAE: 152.7607\n",
      "Epoch: 090, Train MAE: 145.0007, Test MAE: 147.6928\n",
      "Epoch: 091, Train MAE: 144.6468, Test MAE: 156.0565\n",
      "Epoch: 092, Train MAE: 145.0690, Test MAE: 151.3423\n",
      "Epoch: 093, Train MAE: 144.6414, Test MAE: 148.5209\n",
      "Epoch: 094, Train MAE: 144.0039, Test MAE: 165.3416\n",
      "Epoch: 095, Train MAE: 143.9319, Test MAE: 145.2057\n",
      "Epoch: 096, Train MAE: 145.2311, Test MAE: 151.6203\n",
      "Epoch: 097, Train MAE: 144.2211, Test MAE: 147.7550\n",
      "Epoch: 098, Train MAE: 144.7545, Test MAE: 156.5072\n",
      "Epoch: 099, Train MAE: 143.7365, Test MAE: 146.6521\n",
      "Epoch: 100, Train MAE: 144.3849, Test MAE: 149.7359\n",
      "Epoch: 101, Train MAE: 143.5881, Test MAE: 137.2798\n",
      "Epoch: 102, Train MAE: 143.6822, Test MAE: 146.4274\n",
      "Epoch: 103, Train MAE: 144.4395, Test MAE: 145.2078\n",
      "Epoch: 104, Train MAE: 143.8362, Test MAE: 150.9900\n",
      "Epoch: 105, Train MAE: 144.4474, Test MAE: 155.2206\n",
      "Epoch: 106, Train MAE: 143.8502, Test MAE: 157.7690\n",
      "Epoch: 107, Train MAE: 144.1217, Test MAE: 149.7281\n",
      "Epoch: 108, Train MAE: 142.7574, Test MAE: 142.9954\n",
      "Epoch: 109, Train MAE: 143.4909, Test MAE: 147.7822\n",
      "Epoch: 110, Train MAE: 143.3658, Test MAE: 161.4581\n",
      "Epoch: 111, Train MAE: 143.5569, Test MAE: 155.2545\n",
      "Epoch: 112, Train MAE: 143.3936, Test MAE: 160.1654\n",
      "Epoch: 113, Train MAE: 144.5708, Test MAE: 150.3796\n",
      "Epoch: 114, Train MAE: 143.1101, Test MAE: 155.5872\n",
      "Epoch: 115, Train MAE: 143.3381, Test MAE: 147.9833\n",
      "Epoch: 116, Train MAE: 143.0563, Test MAE: 145.3443\n",
      "Epoch: 117, Train MAE: 142.7626, Test MAE: 148.1418\n",
      "Epoch: 118, Train MAE: 143.4289, Test MAE: 160.4269\n",
      "Epoch: 119, Train MAE: 143.2560, Test MAE: 147.1523\n",
      "Epoch: 120, Train MAE: 143.6656, Test MAE: 148.0573\n",
      "Epoch: 121, Train MAE: 142.7055, Test MAE: 154.0308\n",
      "Epoch: 122, Train MAE: 143.1076, Test MAE: 151.9096\n",
      "Epoch: 123, Train MAE: 143.5377, Test MAE: 162.5744\n",
      "Epoch: 124, Train MAE: 143.5530, Test MAE: 157.0652\n",
      "Epoch: 125, Train MAE: 142.4969, Test MAE: 149.4537\n",
      "Epoch: 126, Train MAE: 142.7379, Test MAE: 152.3491\n",
      "Epoch: 127, Train MAE: 143.0972, Test MAE: 148.1843\n",
      "Epoch: 128, Train MAE: 142.6192, Test MAE: 153.1356\n",
      "Epoch: 129, Train MAE: 143.6827, Test MAE: 150.7575\n",
      "Epoch: 130, Train MAE: 142.8269, Test MAE: 152.4309\n",
      "Epoch: 131, Train MAE: 143.1830, Test MAE: 149.7507\n",
      "Epoch: 132, Train MAE: 142.5457, Test MAE: 149.8919\n",
      "Epoch: 133, Train MAE: 142.7750, Test MAE: 153.0828\n",
      "Epoch: 134, Train MAE: 142.9133, Test MAE: 154.6222\n",
      "Epoch: 135, Train MAE: 143.9921, Test MAE: 154.8231\n",
      "Epoch: 136, Train MAE: 143.0679, Test MAE: 149.5118\n",
      "Epoch: 137, Train MAE: 142.7405, Test MAE: 150.1550\n",
      "Epoch: 138, Train MAE: 142.7031, Test MAE: 157.3696\n",
      "Epoch: 139, Train MAE: 143.5680, Test MAE: 152.6388\n",
      "Epoch: 140, Train MAE: 142.3122, Test MAE: 152.4831\n",
      "Epoch: 141, Train MAE: 142.3965, Test MAE: 156.4043\n",
      "Epoch: 142, Train MAE: 143.1056, Test MAE: 152.3991\n",
      "Epoch: 143, Train MAE: 142.9219, Test MAE: 152.0128\n",
      "Epoch: 144, Train MAE: 142.3111, Test MAE: 152.0345\n",
      "Epoch: 145, Train MAE: 142.0734, Test MAE: 154.8527\n",
      "Epoch: 146, Train MAE: 142.1069, Test MAE: 147.8200\n",
      "Epoch: 147, Train MAE: 142.9582, Test MAE: 152.3872\n",
      "Epoch: 148, Train MAE: 142.6971, Test MAE: 152.9268\n",
      "Epoch: 149, Train MAE: 143.0771, Test MAE: 154.4222\n",
      "Epoch: 150, Train MAE: 143.0630, Test MAE: 153.3415\n",
      "Epoch: 151, Train MAE: 142.9137, Test MAE: 151.1261\n",
      "Epoch: 152, Train MAE: 142.7406, Test MAE: 150.6436\n",
      "Epoch: 153, Train MAE: 142.0238, Test MAE: 152.3963\n",
      "Epoch: 154, Train MAE: 142.3034, Test MAE: 151.0194\n",
      "Epoch: 155, Train MAE: 142.3833, Test MAE: 152.3956\n",
      "Epoch: 156, Train MAE: 143.5694, Test MAE: 151.8054\n",
      "Epoch: 157, Train MAE: 142.7022, Test MAE: 153.0693\n",
      "Epoch: 158, Train MAE: 142.2157, Test MAE: 154.2006\n",
      "Epoch: 159, Train MAE: 142.2629, Test MAE: 150.4499\n",
      "Epoch: 160, Train MAE: 142.9966, Test MAE: 153.2184\n",
      "Epoch: 161, Train MAE: 142.6486, Test MAE: 149.5841\n",
      "Epoch: 162, Train MAE: 142.6244, Test MAE: 152.2923\n",
      "Epoch: 163, Train MAE: 143.0854, Test MAE: 155.3380\n",
      "Epoch: 164, Train MAE: 143.3985, Test MAE: 153.1173\n",
      "Epoch: 165, Train MAE: 142.2990, Test MAE: 151.7431\n",
      "Epoch: 166, Train MAE: 143.2221, Test MAE: 155.3042\n",
      "Epoch: 167, Train MAE: 142.4664, Test MAE: 155.3602\n",
      "Epoch: 168, Train MAE: 143.6519, Test MAE: 151.3534\n",
      "Epoch: 169, Train MAE: 142.3015, Test MAE: 153.9629\n",
      "Epoch: 170, Train MAE: 142.4687, Test MAE: 152.5861\n",
      "Epoch: 171, Train MAE: 142.0527, Test MAE: 153.1236\n",
      "Epoch: 172, Train MAE: 141.9288, Test MAE: 155.7343\n",
      "Epoch: 173, Train MAE: 143.3081, Test MAE: 154.1932\n",
      "Epoch: 174, Train MAE: 142.9336, Test MAE: 155.8951\n",
      "Epoch: 175, Train MAE: 142.3888, Test MAE: 152.6833\n",
      "Epoch: 176, Train MAE: 141.3542, Test MAE: 153.2882\n",
      "Epoch: 177, Train MAE: 142.8883, Test MAE: 152.1172\n",
      "Epoch: 178, Train MAE: 142.3588, Test MAE: 154.4946\n",
      "Epoch: 179, Train MAE: 142.9558, Test MAE: 153.8139\n",
      "Epoch: 180, Train MAE: 142.2522, Test MAE: 153.4100\n",
      "Epoch: 181, Train MAE: 143.2226, Test MAE: 152.5835\n",
      "Epoch: 182, Train MAE: 142.3797, Test MAE: 153.6399\n",
      "Epoch: 183, Train MAE: 142.5151, Test MAE: 150.2204\n",
      "Epoch: 184, Train MAE: 143.3059, Test MAE: 151.1646\n",
      "Epoch: 185, Train MAE: 142.6264, Test MAE: 155.0735\n",
      "Epoch: 186, Train MAE: 143.5928, Test MAE: 152.3492\n",
      "Epoch: 187, Train MAE: 142.0795, Test MAE: 153.1750\n",
      "Epoch: 188, Train MAE: 141.5461, Test MAE: 151.2542\n",
      "Epoch: 189, Train MAE: 143.6390, Test MAE: 152.8568\n",
      "Epoch: 190, Train MAE: 142.1392, Test MAE: 155.7944\n",
      "Epoch: 191, Train MAE: 143.0902, Test MAE: 152.4952\n",
      "Epoch: 192, Train MAE: 143.2087, Test MAE: 152.3965\n",
      "Epoch: 193, Train MAE: 142.8592, Test MAE: 155.0227\n",
      "Epoch: 194, Train MAE: 142.0851, Test MAE: 151.7972\n",
      "Epoch: 195, Train MAE: 142.3058, Test MAE: 154.2167\n",
      "Epoch: 196, Train MAE: 142.2355, Test MAE: 153.2559\n",
      "Epoch: 197, Train MAE: 141.8926, Test MAE: 154.0895\n",
      "Epoch: 198, Train MAE: 142.3760, Test MAE: 153.5989\n",
      "Epoch: 199, Train MAE: 143.0490, Test MAE: 153.1775\n",
      "Epoch: 200, Train MAE: 144.2644, Test MAE: 151.6276\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_numGNN2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65625\n",
      "Number of test graphs: 16237\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2ece4-05e7-469a-a880-0eb27fe99531",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "160f8d28-db63-4202-ab0f-64e030d9b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=21, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)\n",
    "\n",
    "model.load_state_dict(torch.load('model/best_SAGE_concat.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out)\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>173.341354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>67.073875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>60.989979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>56.514645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>63.594818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-7.164486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.655503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>-0.521235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-1.570179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-5.174440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   173.341354\n",
       "1      68615                    67.073875\n",
       "2      68616                    60.989979\n",
       "3      68617                    56.514645\n",
       "4      68618                    63.594818\n",
       "...      ...                          ...\n",
       "16995  85609                    -7.164486\n",
       "16996  85610                     1.655503\n",
       "16997  85611                    -0.521235\n",
       "16998  85612                    -1.570179\n",
       "16999  85613                    -5.174440\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfd22f-5ebe-43cd-9621-06a0ddcd6f37",
   "metadata": {},
   "source": [
    "## Create Latent Space for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da5e7a7-88cc-46b5-a7e5-2aca58e7215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=21, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out=nn.Sequential(*list(model.out.children())[:-1])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91628a15-bd6f-4df6-812e-d86634bc8e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n",
      "done: 200\n",
      "done: 300\n",
      "done: 400\n",
      "done: 500\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    train_x.append(out)\n",
    "    train_y.append(data.y.cpu().detach().numpy())\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "train_x = np.concatenate(train_x, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00dc8e64-9c19-401b-864d-13b4539fa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "test_x = []\n",
    "test_mofname = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    test_x.append(out)\n",
    "    test_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "test_x = np.concatenate(test_x, axis=0)\n",
    "test_mofname = np.concatenate(test_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b951cd-46fd-4d9a-b530-cdf6e6cfc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_x)\n",
    "test_df = pd.DataFrame(test_x)\n",
    "\n",
    "train_df['target'] = train_y.flatten()\n",
    "test_df['mofname'] = test_mofname.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cf83f50-e2a7-4ab8-8c32-aec32212f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>mofname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.393690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.533949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.920761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790710</td>\n",
       "      <td>-0.882568</td>\n",
       "      <td>-0.571121</td>\n",
       "      <td>-0.711980</td>\n",
       "      <td>-0.610755</td>\n",
       "      <td>0.547042</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>0.731336</td>\n",
       "      <td>mof_unit_68614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.179619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.036682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.112279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596504</td>\n",
       "      <td>-0.279894</td>\n",
       "      <td>-0.491427</td>\n",
       "      <td>-0.082455</td>\n",
       "      <td>-0.518308</td>\n",
       "      <td>-0.334211</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.067150</td>\n",
       "      <td>-0.585683</td>\n",
       "      <td>mof_unit_68615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.570940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.469352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.490082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085405</td>\n",
       "      <td>0.476304</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.056075</td>\n",
       "      <td>-0.334211</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.101586</td>\n",
       "      <td>-0.637351</td>\n",
       "      <td>mof_unit_68616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.089923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.092972</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352204</td>\n",
       "      <td>0.873918</td>\n",
       "      <td>0.453466</td>\n",
       "      <td>-0.711980</td>\n",
       "      <td>-0.980542</td>\n",
       "      <td>0.742876</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.123961</td>\n",
       "      <td>-0.594873</td>\n",
       "      <td>mof_unit_68617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.540619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.358086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.436696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736885</td>\n",
       "      <td>0.782988</td>\n",
       "      <td>0.352755</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.333415</td>\n",
       "      <td>-0.138377</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.102154</td>\n",
       "      <td>-0.468214</td>\n",
       "      <td>mof_unit_68618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.088397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.394831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.958029</td>\n",
       "      <td>3.118466</td>\n",
       "      <td>5.937423</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.795648</td>\n",
       "      <td>-0.627962</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.156696</td>\n",
       "      <td>-1.963071</td>\n",
       "      <td>mof_unit_85609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16233</th>\n",
       "      <td>0.313762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443608</td>\n",
       "      <td>0.289820</td>\n",
       "      <td>0.350841</td>\n",
       "      <td>0.267429</td>\n",
       "      <td>...</td>\n",
       "      <td>1.714540</td>\n",
       "      <td>2.005436</td>\n",
       "      <td>1.721716</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.980542</td>\n",
       "      <td>-0.921714</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.142419</td>\n",
       "      <td>-1.605460</td>\n",
       "      <td>mof_unit_85610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16234</th>\n",
       "      <td>0.248444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590385</td>\n",
       "      <td>0.052065</td>\n",
       "      <td>0.573007</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.912784</td>\n",
       "      <td>1.749141</td>\n",
       "      <td>1.644934</td>\n",
       "      <td>-0.711980</td>\n",
       "      <td>-0.425862</td>\n",
       "      <td>0.253291</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.155858</td>\n",
       "      <td>-1.651416</td>\n",
       "      <td>mof_unit_85611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16235</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.944257</td>\n",
       "      <td>2.093103</td>\n",
       "      <td>2.144743</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.425862</td>\n",
       "      <td>0.449125</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.154843</td>\n",
       "      <td>-1.748159</td>\n",
       "      <td>mof_unit_85612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16236</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.708716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.926558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.436823</td>\n",
       "      <td>2.762963</td>\n",
       "      <td>4.032448</td>\n",
       "      <td>-1.026742</td>\n",
       "      <td>-0.888095</td>\n",
       "      <td>0.644959</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.158366</td>\n",
       "      <td>-1.946889</td>\n",
       "      <td>mof_unit_85613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16237 rows  278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3    4    5         6          7         8  \\\n",
       "0      28.393690  0.0  0.0  0.0  0.0  0.0  0.000000  30.533949  0.000000   \n",
       "1      10.179619  0.0  0.0  0.0  0.0  0.0  0.000000  11.036682  0.000000   \n",
       "2       9.570940  0.0  0.0  0.0  0.0  0.0  0.000000  10.469352  0.000000   \n",
       "3       8.316006  0.0  0.0  0.0  0.0  0.0  0.000000   9.089923  0.000000   \n",
       "4       9.540619  0.0  0.0  0.0  0.0  0.0  0.000000  10.358086  0.000000   \n",
       "...          ...  ...  ...  ...  ...  ...       ...        ...       ...   \n",
       "16232   0.000000  0.0  0.0  0.0  0.0  0.0  2.088397   0.000000  2.394831   \n",
       "16233   0.313762  0.0  0.0  0.0  0.0  0.0  0.443608   0.289820  0.350841   \n",
       "16234   0.248444  0.0  0.0  0.0  0.0  0.0  0.590385   0.052065  0.573007   \n",
       "16235   0.000000  0.0  0.0  0.0  0.0  0.0  0.856547   0.000000  0.859740   \n",
       "16236   0.000000  0.0  0.0  0.0  0.0  0.0  1.708716   0.000000  1.926558   \n",
       "\n",
       "               9  ...       268       269       270       271       272  \\\n",
       "0      30.920761  ... -0.790710 -0.882568 -0.571121 -0.711980 -0.610755   \n",
       "1      11.112279  ... -0.596504 -0.279894 -0.491427 -0.082455 -0.518308   \n",
       "2      10.490082  ...  1.085405  0.476304  0.123035 -0.397217 -0.056075   \n",
       "3       9.092972  ...  1.352204  0.873918  0.453466 -0.711980 -0.980542   \n",
       "4      10.436696  ...  0.736885  0.782988  0.352755 -0.397217 -0.333415   \n",
       "...          ...  ...       ...       ...       ...       ...       ...   \n",
       "16232   0.000000  ...  2.958029  3.118466  5.937423 -0.397217 -0.795648   \n",
       "16233   0.267429  ...  1.714540  2.005436  1.721716 -0.397217 -0.980542   \n",
       "16234   0.023652  ...  1.912784  1.749141  1.644934 -0.711980 -0.425862   \n",
       "16235   0.000000  ...  1.944257  2.093103  2.144743 -0.397217 -0.425862   \n",
       "16236   0.000000  ...  2.436823  2.762963  4.032448 -1.026742 -0.888095   \n",
       "\n",
       "            273       274       275       276         mofname  \n",
       "0      0.547042  0.359778  0.050804  0.731336  mof_unit_68614  \n",
       "1     -0.334211  0.359778 -0.067150 -0.585683  mof_unit_68615  \n",
       "2     -0.334211  0.359778 -0.101586 -0.637351  mof_unit_68616  \n",
       "3      0.742876  0.359778 -0.123961 -0.594873  mof_unit_68617  \n",
       "4     -0.138377  0.359778 -0.102154 -0.468214  mof_unit_68618  \n",
       "...         ...       ...       ...       ...             ...  \n",
       "16232 -0.627962 -2.779491 -0.156696 -1.963071  mof_unit_85609  \n",
       "16233 -0.921714 -2.779491 -0.142419 -1.605460  mof_unit_85610  \n",
       "16234  0.253291 -2.779491 -0.155858 -1.651416  mof_unit_85611  \n",
       "16235  0.449125 -2.779491 -0.154843 -1.748159  mof_unit_85612  \n",
       "16236  0.644959 -2.779491 -0.158366 -1.946889  mof_unit_85613  \n",
       "\n",
       "[16237 rows x 278 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c59a166-f0e8-438e-95fb-49c5fa3af489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train/auto_SAGE_feat_train.csv',index=False)\n",
    "test_df.to_csv('data/test/auto_SAGE_feat_mofname_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12171eea-b02a-49f7-b95d-493d132fec69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

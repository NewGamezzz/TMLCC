{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, GraphConv, SAGEConv, DenseSAGEConv, DenseGraphConv, ChebConv, dense_mincut_pool, global_add_pool, global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.utils import generate_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649af641-29ad-4fa4-a247-173f109ad226",
   "metadata": {},
   "source": [
    "## Create Custom Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08c1f42-8508-4aac-a893-e69000ffb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOFData(Data):\n",
    "    def __init__(self, mof_node = None, mof_edge_index = None, mof_edge_attr = None,\n",
    "                        metal_node = None, metal_edge_index = None, metal_edge_attr = None,\n",
    "                        organ1_node = None, organ1_edge_index = None, organ1_edge_attr = None,\n",
    "                        organ2_node = None, organ2_edge_index = None, organ2_edge_attr = None,\n",
    "                        mofname = None, x_feat = None, y = None):\n",
    "        super().__init__()\n",
    "        self.mof_node = mof_node\n",
    "        self.mof_edge_index = mof_edge_index\n",
    "        self.mof_edge_attr = mof_edge_attr\n",
    "        \n",
    "        self.metal_node = metal_node\n",
    "        self.metal_edge_index = metal_edge_index\n",
    "        self.metal_edge_attr = metal_edge_attr\n",
    "        \n",
    "        self.organ1_node = organ1_node\n",
    "        self.organ1_edge_index = organ1_edge_index\n",
    "        self.organ1_edge_attr = organ1_edge_attr\n",
    "        \n",
    "        self.organ2_node = organ2_node\n",
    "        self.organ2_edge_index = organ2_edge_index\n",
    "        self.organ2_edge_attr = organ2_edge_attr\n",
    "        \n",
    "        self.mofname = mofname\n",
    "        self.x_feat = x_feat\n",
    "        self.y = y\n",
    "        \n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'mof_edge_index':\n",
    "            return self.mof_node.size(0)\n",
    "        if key == 'metal_edge_index':\n",
    "            return self.metal_node.size(0)\n",
    "        if key == 'organ1_edge_index':\n",
    "            return self.organ1_node.size(0)\n",
    "        if key == 'organ2_edge_index':\n",
    "            return self.organ2_node.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOFname                                          0\n",
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(17000, 25)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test/clean_test_linker.csv')\n",
    "smiles = pd.read_csv('data/test/smiles_test.csv')\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "# data = data.drop('Unnamed: 0', axis=1)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "drop_feat = ['MOFname', 'weight [u]', 'functional_groups', 'Smiles', 'metal_linker', 'organic_linker1', 'organic_linker2'] #, 'CO2_working_capacity [mL/g]'\n",
    "c = 1\n",
    "for _, line in data.iterrows():\n",
    "    mof = Chem.MolFromSmiles(line['Smiles'])\n",
    "    metal = Chem.MolFromSmiles(line['metal_linker'])\n",
    "    organ1 = Chem.MolFromSmiles(line['organic_linker1'])\n",
    "    organ2 = Chem.MolFromSmiles(line['organic_linker2'])\n",
    "    \n",
    "    if mof == None or metal == None or organ1 == None or organ2 == None:  #or metal == None or organ1 == None or organ2 == None\n",
    "        continue\n",
    "    \n",
    "    mof_node, mof_edge_index, mof_edge_attr = generate_graph(mof)\n",
    "    metal_node, metal_edge_index, metal_edge_attr = generate_graph(metal)\n",
    "    organ1_node, organ1_edge_index, organ1_edge_attr = generate_graph(organ1)\n",
    "    organ2_node, organ2_edge_index, organ2_edge_attr = generate_graph(organ2)\n",
    "\n",
    "\n",
    "    x_feat = line.drop(drop_feat).values.astype(float)\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "#     y=torch.tensor([line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    \n",
    "    data_d = MOFData(mof_node = mof_node, mof_edge_index = mof_edge_index, mof_edge_attr = mof_edge_attr,\n",
    "                  metal_node = metal_node, metal_edge_index = metal_edge_index, metal_edge_attr = metal_edge_attr,\n",
    "                  organ1_node = organ1_node, organ1_edge_index = organ1_edge_index, organ1_edge_attr = organ1_edge_attr,\n",
    "                  organ2_node = organ2_node, organ2_edge_index = organ2_edge_index, organ2_edge_attr = organ2_edge_attr,\n",
    "                  mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "#     data_d.mof_num_nodes = len(mof.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_concat_linker_replace_surface.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 55120\n",
      "Number of test graphs: 10500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.16, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels, num_of_centers=20):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.pool1 = Linear(dim, num_of_centers)\n",
    "        self.conv4 = DenseSAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "#         x = self.conv3(x, edge_index).relu()\n",
    "        \n",
    "        x, mask = to_dense_batch(x, batch) \n",
    "        adj = to_dense_adj(edge_index, batch)\n",
    "        s = self.pool1(x)\n",
    "        \n",
    "        x, adj, mincut_loss, ortho_loss = dense_mincut_pool(x, adj, s, mask)\n",
    "        \n",
    "        x = self.conv4(x, adj).relu()\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin(x).relu()\n",
    "        return x, mincut_loss, ortho_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ffba7f3-45e4-495d-a44d-8c9bd2fb90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels, num_of_centers=20):\n",
    "        super(Graph, self).__init__()\n",
    "        self.conv1 = GraphConv(in_channels, dim)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.conv3 = GraphConv(dim, dim)\n",
    "        self.pool1 = Linear(dim, num_of_centers)\n",
    "        self.conv4 = DenseGraphConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "#         x = self.conv3(x, edge_index).relu()\n",
    "        \n",
    "        x, mask = to_dense_batch(x, batch) \n",
    "        adj = to_dense_adj(edge_index, batch)\n",
    "        s = self.pool1(x)\n",
    "        \n",
    "        x, adj, mincut_loss, ortho_loss = dense_mincut_pool(x, adj, s, mask)\n",
    "        \n",
    "        x = self.conv4(x, adj).relu()\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin(x).relu()\n",
    "        return x, mincut_loss, ortho_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_mof, in_metal, in_organ1, in_organ2, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.mof_g = SAGE(in_mof, dim, 128) # SAGE\n",
    "        self.metal_g = Graph(in_metal, dim, 128)\n",
    "        self.organ1_g = Graph(in_organ1, dim, 128)\n",
    "        self.organ2_g = Graph(in_organ2, dim, 128)\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(256, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256 + 128*3, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, mof_node, mof_edge_index, mof_node_batch, \n",
    "                      metal_node, metal_edge_index, metal_node_batch,\n",
    "                      organ1_node, organ1_edge_index, organ1_node_batch,\n",
    "                      organ2_node, organ2_edge_index, organ2_node_batch, x_feat):\n",
    "        \n",
    "        mof, mof_mincut_loss, mof_ortho_loss = self.mof_g(mof_node, mof_edge_index, mof_node_batch)\n",
    "        metal, metal_mincut_loss, metal_ortho_loss = self.metal_g(metal_node, metal_edge_index, metal_node_batch)\n",
    "        organ1, organ1_mincut_loss, organ1_ortho_loss = self.organ1_g(organ1_node, organ1_edge_index, organ1_node_batch)\n",
    "        organ2, organ2_mincut_loss, organ2_ortho_loss = self.organ2_g(organ2_node, organ2_edge_index, organ2_node_batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        \n",
    "        concat = torch.cat((mof, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross, metal, organ1, organ2), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        out = self.out(x)\n",
    "        return out, mof_mincut_loss + mof_ortho_loss + metal_mincut_loss + metal_ortho_loss + organ1_mincut_loss + organ1_ortho_loss + organ2_mincut_loss + organ2_ortho_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out, pool_loss = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y) + pool_loss  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy() - pool_loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out, pool_loss = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y) + pool_loss  # Compute the loss.\n",
    "        correct+=loss.cpu().detach().numpy() - pool_loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mof_node = 9\n",
    "num_metal_node = 9\n",
    "num_organ1_node = 9\n",
    "num_organ2_node = 9\n",
    "hidden_channels = 32 # SAGE: 32\n",
    "num_feats = 18\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_mof_node, num_metal_node, num_organ1_node, num_organ2_node, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001) #factor=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 37.4608, Test MAE: 26.2974\n",
      "Epoch: 002, Train MAE: 26.1060, Test MAE: 23.2140\n",
      "Epoch: 003, Train MAE: 24.2635, Test MAE: 23.3522\n",
      "Epoch: 004, Train MAE: 23.2698, Test MAE: 23.6859\n",
      "Epoch: 005, Train MAE: 22.9477, Test MAE: 21.3307\n",
      "Epoch: 006, Train MAE: 22.8410, Test MAE: 21.1939\n",
      "Epoch: 007, Train MAE: 22.1977, Test MAE: 21.6888\n",
      "Epoch: 008, Train MAE: 22.2351, Test MAE: 20.8897\n",
      "Epoch: 009, Train MAE: 22.3834, Test MAE: 20.6114\n",
      "Epoch: 010, Train MAE: 22.4387, Test MAE: 22.1569\n",
      "Epoch: 011, Train MAE: 22.0160, Test MAE: 20.6636\n",
      "Epoch: 012, Train MAE: 21.8224, Test MAE: 21.7065\n",
      "Epoch: 013, Train MAE: 21.7253, Test MAE: 20.1260\n",
      "Epoch: 014, Train MAE: 21.6161, Test MAE: 19.9027\n",
      "Epoch: 015, Train MAE: 21.1808, Test MAE: 20.4244\n",
      "Epoch: 016, Train MAE: 21.2526, Test MAE: 22.8809\n",
      "Epoch: 017, Train MAE: 21.4786, Test MAE: 19.9083\n",
      "Epoch: 018, Train MAE: 20.9490, Test MAE: 20.0091\n",
      "Epoch: 019, Train MAE: 20.8059, Test MAE: 20.5903\n",
      "Epoch: 020, Train MAE: 20.8070, Test MAE: 19.5984\n",
      "Epoch: 021, Train MAE: 20.8229, Test MAE: 20.2886\n",
      "Epoch: 022, Train MAE: 20.7342, Test MAE: 19.9071\n",
      "Epoch: 023, Train MAE: 20.6841, Test MAE: 19.7606\n",
      "Epoch: 024, Train MAE: 20.6523, Test MAE: 19.5395\n",
      "Epoch: 025, Train MAE: 20.4608, Test MAE: 19.3265\n",
      "Epoch: 026, Train MAE: 20.5951, Test MAE: 19.7769\n",
      "Epoch: 027, Train MAE: 20.5324, Test MAE: 19.7410\n",
      "Epoch: 028, Train MAE: 20.3436, Test MAE: 19.5438\n",
      "Epoch: 029, Train MAE: 20.3959, Test MAE: 20.1763\n",
      "Epoch: 030, Train MAE: 20.2768, Test MAE: 19.6808\n",
      "Epoch: 031, Train MAE: 20.1646, Test MAE: 19.1923\n",
      "Epoch: 032, Train MAE: 20.0546, Test MAE: 19.0093\n",
      "Epoch: 033, Train MAE: 20.1016, Test MAE: 19.2737\n",
      "Epoch: 034, Train MAE: 20.0913, Test MAE: 19.5408\n",
      "Epoch: 035, Train MAE: 20.0151, Test MAE: 19.4896\n",
      "Epoch: 036, Train MAE: 20.0089, Test MAE: 19.5478\n",
      "Epoch: 037, Train MAE: 19.8665, Test MAE: 18.9874\n",
      "Epoch: 038, Train MAE: 19.8528, Test MAE: 22.9091\n",
      "Epoch: 039, Train MAE: 19.9320, Test MAE: 19.5477\n",
      "Epoch: 040, Train MAE: 19.6913, Test MAE: 19.0528\n",
      "Epoch: 041, Train MAE: 19.8130, Test MAE: 19.1189\n",
      "Epoch: 042, Train MAE: 19.6301, Test MAE: 19.4852\n",
      "Epoch: 043, Train MAE: 19.5072, Test MAE: 18.9661\n",
      "Epoch: 044, Train MAE: 19.5297, Test MAE: 18.8953\n",
      "Epoch: 045, Train MAE: 19.5126, Test MAE: 18.7785\n",
      "Epoch: 046, Train MAE: 19.3837, Test MAE: 18.8277\n",
      "Epoch: 047, Train MAE: 19.3960, Test MAE: 19.4753\n",
      "Epoch: 048, Train MAE: 19.3784, Test MAE: 19.2890\n",
      "Epoch: 049, Train MAE: 19.3336, Test MAE: 18.8967\n",
      "Epoch: 050, Train MAE: 19.3029, Test MAE: 19.0745\n",
      "Epoch: 051, Train MAE: 19.3216, Test MAE: 18.9478\n",
      "Epoch: 052, Train MAE: 19.1720, Test MAE: 19.1608\n",
      "Epoch: 053, Train MAE: 19.2647, Test MAE: 18.7329\n",
      "Epoch: 054, Train MAE: 19.1601, Test MAE: 18.8916\n",
      "Epoch: 055, Train MAE: 19.1872, Test MAE: 19.4602\n",
      "Epoch: 056, Train MAE: 19.2140, Test MAE: 19.0177\n",
      "Epoch: 057, Train MAE: 18.9637, Test MAE: 18.9195\n",
      "Epoch: 058, Train MAE: 19.0673, Test MAE: 19.4122\n",
      "Epoch: 059, Train MAE: 18.9917, Test MAE: 18.7278\n",
      "Epoch: 060, Train MAE: 18.9378, Test MAE: 18.6516\n",
      "Epoch: 061, Train MAE: 18.8945, Test MAE: 18.6903\n",
      "Epoch: 062, Train MAE: 18.9072, Test MAE: 18.6782\n",
      "Epoch: 063, Train MAE: 18.8607, Test MAE: 18.9498\n",
      "Epoch: 064, Train MAE: 18.9059, Test MAE: 18.9658\n",
      "Epoch: 065, Train MAE: 18.7977, Test MAE: 18.6301\n",
      "Epoch: 066, Train MAE: 18.7129, Test MAE: 18.7014\n",
      "Epoch: 067, Train MAE: 18.7709, Test MAE: 18.9003\n",
      "Epoch: 068, Train MAE: 18.7231, Test MAE: 18.8243\n",
      "Epoch: 069, Train MAE: 18.7968, Test MAE: 18.6340\n",
      "Epoch: 070, Train MAE: 18.6257, Test MAE: 18.5625\n",
      "Epoch: 071, Train MAE: 18.5517, Test MAE: 18.5785\n",
      "Epoch: 072, Train MAE: 18.5560, Test MAE: 18.6569\n",
      "Epoch: 073, Train MAE: 18.5635, Test MAE: 18.5260\n",
      "Epoch: 074, Train MAE: 18.5574, Test MAE: 18.4931\n",
      "Epoch: 075, Train MAE: 18.5675, Test MAE: 18.6200\n",
      "Epoch: 076, Train MAE: 18.5223, Test MAE: 18.6801\n",
      "Epoch: 077, Train MAE: 18.4499, Test MAE: 18.7138\n",
      "Epoch: 078, Train MAE: 18.4929, Test MAE: 18.6603\n",
      "Epoch: 079, Train MAE: 18.3696, Test MAE: 18.6406\n",
      "Epoch: 080, Train MAE: 18.4012, Test MAE: 18.5021\n",
      "Epoch: 081, Train MAE: 18.3927, Test MAE: 18.5018\n",
      "Epoch: 082, Train MAE: 18.4206, Test MAE: 18.5810\n",
      "Epoch: 083, Train MAE: 18.3632, Test MAE: 18.5226\n",
      "Epoch: 084, Train MAE: 18.2787, Test MAE: 18.5146\n",
      "Epoch: 085, Train MAE: 18.2564, Test MAE: 18.5226\n",
      "Epoch: 086, Train MAE: 18.2648, Test MAE: 18.5446\n",
      "Epoch: 087, Train MAE: 18.2222, Test MAE: 18.5044\n",
      "Epoch: 088, Train MAE: 18.1695, Test MAE: 18.7889\n",
      "Epoch: 089, Train MAE: 18.1559, Test MAE: 18.5346\n",
      "Epoch: 090, Train MAE: 18.1107, Test MAE: 18.5370\n",
      "Epoch: 091, Train MAE: 18.1229, Test MAE: 18.4624\n",
      "Epoch: 092, Train MAE: 18.0922, Test MAE: 18.4380\n",
      "Epoch: 093, Train MAE: 18.0590, Test MAE: 18.5718\n",
      "Epoch: 094, Train MAE: 18.1192, Test MAE: 18.4910\n",
      "Epoch: 095, Train MAE: 18.1092, Test MAE: 18.5594\n",
      "Epoch: 096, Train MAE: 18.1261, Test MAE: 18.6762\n",
      "Epoch: 097, Train MAE: 17.9921, Test MAE: 18.4631\n",
      "Epoch: 098, Train MAE: 18.0222, Test MAE: 18.4827\n",
      "Epoch: 099, Train MAE: 17.9459, Test MAE: 18.5545\n",
      "Epoch: 100, Train MAE: 17.9747, Test MAE: 18.4762\n",
      "Epoch: 101, Train MAE: 17.9512, Test MAE: 18.4687\n",
      "Epoch: 102, Train MAE: 17.9398, Test MAE: 18.3954\n",
      "Epoch: 103, Train MAE: 17.8799, Test MAE: 18.5786\n",
      "Epoch: 104, Train MAE: 17.8811, Test MAE: 18.7373\n",
      "Epoch: 105, Train MAE: 17.9155, Test MAE: 18.6739\n",
      "Epoch: 106, Train MAE: 17.9179, Test MAE: 18.5136\n",
      "Epoch: 107, Train MAE: 17.8554, Test MAE: 18.4481\n",
      "Epoch: 108, Train MAE: 17.8630, Test MAE: 18.4261\n",
      "Epoch: 109, Train MAE: 17.8231, Test MAE: 18.5247\n",
      "Epoch: 110, Train MAE: 17.8279, Test MAE: 18.5645\n",
      "Epoch: 111, Train MAE: 17.8442, Test MAE: 18.4625\n",
      "Epoch: 112, Train MAE: 17.7980, Test MAE: 18.5062\n",
      "Epoch: 113, Train MAE: 17.7860, Test MAE: 18.4340\n",
      "Epoch: 114, Train MAE: 17.8235, Test MAE: 18.4435\n",
      "Epoch: 115, Train MAE: 17.7324, Test MAE: 18.4771\n",
      "Epoch: 116, Train MAE: 17.6633, Test MAE: 18.4564\n",
      "Epoch: 117, Train MAE: 17.7601, Test MAE: 18.4674\n",
      "Epoch: 118, Train MAE: 17.6945, Test MAE: 18.4366\n",
      "Epoch: 119, Train MAE: 17.6649, Test MAE: 18.4347\n",
      "Epoch: 120, Train MAE: 17.6983, Test MAE: 18.4927\n",
      "Epoch: 121, Train MAE: 17.6748, Test MAE: 18.4625\n",
      "Epoch: 122, Train MAE: 17.7588, Test MAE: 18.4250\n",
      "Epoch: 123, Train MAE: 17.6710, Test MAE: 18.4675\n",
      "Epoch: 124, Train MAE: 17.6370, Test MAE: 18.4776\n",
      "Epoch: 125, Train MAE: 17.6327, Test MAE: 18.4771\n",
      "Epoch: 126, Train MAE: 17.6360, Test MAE: 18.4435\n",
      "Epoch: 127, Train MAE: 17.5903, Test MAE: 18.4590\n",
      "Epoch: 128, Train MAE: 17.6071, Test MAE: 18.4791\n",
      "Epoch: 129, Train MAE: 17.5659, Test MAE: 18.4325\n",
      "Epoch: 130, Train MAE: 17.6496, Test MAE: 18.4666\n",
      "Epoch: 131, Train MAE: 17.5947, Test MAE: 18.4786\n",
      "Epoch: 132, Train MAE: 17.6157, Test MAE: 18.4669\n",
      "Epoch: 133, Train MAE: 17.6627, Test MAE: 18.4774\n",
      "Epoch: 134, Train MAE: 17.5699, Test MAE: 18.4932\n",
      "Epoch: 135, Train MAE: 17.5584, Test MAE: 18.4785\n",
      "Epoch: 136, Train MAE: 17.5949, Test MAE: 18.4515\n",
      "Epoch: 137, Train MAE: 17.5494, Test MAE: 18.4670\n",
      "Epoch: 138, Train MAE: 17.6120, Test MAE: 18.4916\n",
      "Epoch: 139, Train MAE: 17.5722, Test MAE: 18.4628\n",
      "Epoch: 140, Train MAE: 17.5951, Test MAE: 18.4653\n",
      "Epoch: 141, Train MAE: 17.5587, Test MAE: 18.4506\n",
      "Epoch: 142, Train MAE: 17.5081, Test MAE: 18.4507\n",
      "Epoch: 143, Train MAE: 17.6121, Test MAE: 18.4709\n",
      "Epoch: 144, Train MAE: 17.5252, Test MAE: 18.4804\n",
      "Epoch: 145, Train MAE: 17.5152, Test MAE: 18.4717\n",
      "Epoch: 146, Train MAE: 17.5569, Test MAE: 18.4829\n",
      "Epoch: 147, Train MAE: 17.4719, Test MAE: 18.4582\n",
      "Epoch: 148, Train MAE: 17.5319, Test MAE: 18.4840\n",
      "Epoch: 149, Train MAE: 17.5683, Test MAE: 18.4704\n",
      "Epoch: 150, Train MAE: 17.5006, Test MAE: 18.4687\n",
      "Epoch: 151, Train MAE: 17.4877, Test MAE: 18.4722\n",
      "Epoch: 152, Train MAE: 17.4987, Test MAE: 18.4556\n",
      "Epoch: 153, Train MAE: 17.4963, Test MAE: 18.4688\n",
      "Epoch: 154, Train MAE: 17.5070, Test MAE: 18.4642\n",
      "Epoch: 155, Train MAE: 17.4813, Test MAE: 18.4821\n",
      "Epoch: 156, Train MAE: 17.5314, Test MAE: 18.4780\n",
      "Epoch: 157, Train MAE: 17.5238, Test MAE: 18.4765\n",
      "Epoch: 158, Train MAE: 17.5085, Test MAE: 18.4471\n",
      "Epoch: 159, Train MAE: 17.4870, Test MAE: 18.4990\n",
      "Epoch: 160, Train MAE: 17.4795, Test MAE: 18.4717\n",
      "Epoch: 161, Train MAE: 17.5204, Test MAE: 18.4591\n",
      "Epoch: 162, Train MAE: 17.5238, Test MAE: 18.4682\n",
      "Epoch: 163, Train MAE: 17.5374, Test MAE: 18.4819\n",
      "Epoch: 164, Train MAE: 17.4981, Test MAE: 18.4718\n",
      "Epoch: 165, Train MAE: 17.4715, Test MAE: 18.4735\n",
      "Epoch: 166, Train MAE: 17.5278, Test MAE: 18.4931\n",
      "Epoch: 167, Train MAE: 17.4310, Test MAE: 18.4643\n",
      "Epoch: 168, Train MAE: 17.4312, Test MAE: 18.4621\n",
      "Epoch: 169, Train MAE: 17.5244, Test MAE: 18.4611\n",
      "Epoch: 170, Train MAE: 17.4073, Test MAE: 18.4695\n",
      "Epoch: 171, Train MAE: 17.4992, Test MAE: 18.4671\n",
      "Epoch: 172, Train MAE: 17.4818, Test MAE: 18.4775\n",
      "Epoch: 173, Train MAE: 17.4384, Test MAE: 18.4649\n",
      "Epoch: 174, Train MAE: 17.5255, Test MAE: 18.4623\n",
      "Epoch: 175, Train MAE: 17.4637, Test MAE: 18.4788\n",
      "Epoch: 176, Train MAE: 17.5232, Test MAE: 18.4727\n",
      "Epoch: 177, Train MAE: 17.4644, Test MAE: 18.4689\n",
      "Epoch: 178, Train MAE: 17.4227, Test MAE: 18.4699\n",
      "Epoch: 179, Train MAE: 17.4524, Test MAE: 18.4633\n",
      "Epoch: 180, Train MAE: 17.4406, Test MAE: 18.4693\n",
      "Epoch: 181, Train MAE: 17.4821, Test MAE: 18.4671\n",
      "Epoch: 182, Train MAE: 17.4322, Test MAE: 18.4760\n",
      "Epoch: 183, Train MAE: 17.4388, Test MAE: 18.4637\n",
      "Epoch: 184, Train MAE: 17.4712, Test MAE: 18.4715\n",
      "Epoch: 185, Train MAE: 17.5540, Test MAE: 18.4679\n",
      "Epoch: 186, Train MAE: 17.4977, Test MAE: 18.4693\n",
      "Epoch: 187, Train MAE: 17.4749, Test MAE: 18.4659\n",
      "Epoch: 188, Train MAE: 17.5466, Test MAE: 18.4650\n",
      "Epoch: 189, Train MAE: 17.4161, Test MAE: 18.4681\n",
      "Epoch: 190, Train MAE: 17.5147, Test MAE: 18.4679\n",
      "Epoch: 191, Train MAE: 17.4710, Test MAE: 18.4695\n",
      "Epoch: 192, Train MAE: 17.4913, Test MAE: 18.4724\n",
      "Epoch: 193, Train MAE: 17.4816, Test MAE: 18.4693\n",
      "Epoch: 194, Train MAE: 17.4009, Test MAE: 18.4713\n",
      "Epoch: 195, Train MAE: 17.4387, Test MAE: 18.4670\n",
      "Epoch: 196, Train MAE: 17.4191, Test MAE: 18.4725\n",
      "Epoch: 197, Train MAE: 17.4186, Test MAE: 18.4658\n",
      "Epoch: 198, Train MAE: 17.4676, Test MAE: 18.4618\n",
      "Epoch: 199, Train MAE: 17.4888, Test MAE: 18.4675\n",
      "Epoch: 200, Train MAE: 17.4251, Test MAE: 18.4677\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_linkerGNNminCut.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65620\n",
      "Number of test graphs: 16235\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat_linker_replace_surface.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat_linker.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2ece4-05e7-469a-a880-0eb27fe99531",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "160f8d28-db63-4202-ab0f-64e030d9b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (mof_g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (metal_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ1_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ2_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=18, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=640, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_mof_node = 9\n",
    "num_metal_node = 9\n",
    "num_organ1_node = 9\n",
    "num_organ2_node = 9\n",
    "hidden_channels = 32 # SAGE: 32\n",
    "num_feats = 18\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_mof_node, num_metal_node, num_organ1_node, num_organ2_node, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001) #factor=0.85\n",
    "\n",
    "model.load_state_dict(torch.load('model/best_linkerGNNminCut.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out, pool_loss = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                            data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                            data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                            data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float())\n",
    "    \n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out.cpu().detach().numpy())\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>192.599228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>66.363136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>67.216171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>55.901829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>64.024391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-5.661958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.520870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>-0.013260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-0.944833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-3.797317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   192.599228\n",
       "1      68615                    66.363136\n",
       "2      68616                    67.216171\n",
       "3      68617                    55.901829\n",
       "4      68618                    64.024391\n",
       "...      ...                          ...\n",
       "16995  85609                    -5.661958\n",
       "16996  85610                     1.520870\n",
       "16997  85611                    -0.013260\n",
       "16998  85612                    -0.944833\n",
       "16999  85613                    -3.797317\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfd22f-5ebe-43cd-9621-06a0ddcd6f37",
   "metadata": {},
   "source": [
    "## Create Latent Space for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3da5e7a7-88cc-46b5-a7e5-2aca58e7215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (mof_g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (metal_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ1_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ2_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=18, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=640, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out=nn.Sequential(*list(model.out.children())[:-1])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "91628a15-bd6f-4df6-812e-d86634bc8e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n",
      "done: 200\n",
      "done: 300\n",
      "done: 400\n",
      "done: 500\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "train_x = []\n",
    "train_y = []\n",
    "train_mofname = []\n",
    "\n",
    "for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    train_x.append(out)\n",
    "    train_y.append(data.y.cpu().detach().numpy())\n",
    "    train_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "train_x = np.concatenate(train_x, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "train_mofname = np.concatenate(train_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "00dc8e64-9c19-401b-864d-13b4539fa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\data\\storage.py:249: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'organ2_edge_index', 'mof_edge_index', 'x_feat', 'metal_edge_index', 'organ1_edge_index', 'metal_edge_attr', 'organ2_node', 'mofname', 'organ2_edge_attr', 'organ1_node', 'organ1_edge_attr', 'metal_node', 'mof_edge_attr', 'mof_node'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  \" to suppress this warning\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "test_x = []\n",
    "test_mofname = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    test_x.append(out)\n",
    "    test_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "test_x = np.concatenate(test_x, axis=0)\n",
    "test_mofname = np.concatenate(test_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a8b951cd-46fd-4d9a-b530-cdf6e6cfc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_x)\n",
    "test_df = pd.DataFrame(test_x)\n",
    "\n",
    "train_df['target'] = train_y.flatten()\n",
    "test_df['mofname'] = test_mofname.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9c59a166-f0e8-438e-95fb-49c5fa3af489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train/Latent_SAGEGNN_feat_linker_train.csv',index=False)\n",
    "test_df.to_csv('data/test/auto_SAGEGNN_feat_linker_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12171eea-b02a-49f7-b95d-493d132fec69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

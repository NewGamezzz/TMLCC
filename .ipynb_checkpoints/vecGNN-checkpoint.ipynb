{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, SAGEConv, global_add_pool, global_mean_pool\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "MOFname                                          0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "CO2_working_capacity [mL/g]                      0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(68611, 26)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/clean_train.csv')\n",
    "smiles = pd.read_csv('data/train/smiles_train.csv')\n",
    "mol2vec = pickle.load(open('data/train/mol2vec.pkl', 'rb'))\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "mask = ~data['Smiles'].isnull().values\n",
    "mol2vec = mol2vec[mask]\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e11f0e34-b17a-4f43-9a1a-0b4f0d2fc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = {\n",
    "    'atomic_num':\n",
    "    list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED',\n",
    "        'CHI_TETRAHEDRAL_CW',\n",
    "        'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER',\n",
    "    ],\n",
    "    'degree':\n",
    "    list(range(0, 11)),\n",
    "    'formal_charge':\n",
    "    list(range(-5, 7)),\n",
    "    'num_hs':\n",
    "    list(range(0, 9)),\n",
    "    'num_radical_electrons':\n",
    "    list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED',\n",
    "        'S',\n",
    "        'SP',\n",
    "        'SP2',\n",
    "        'SP3',\n",
    "        'SP3D',\n",
    "        'SP3D2',\n",
    "        'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "}\n",
    "\n",
    "e_map = {\n",
    "    'bond_type': [\n",
    "        'misc',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'AROMATIC',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "        'STEREOANY',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n",
      "done: 20000\n",
      "done: 30000\n",
      "done: 40000\n",
      "done: 50000\n",
      "done: 60000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "c = 1\n",
    "for idx, line in data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(line['Smiles'])\n",
    "    \n",
    "    if mol == None:\n",
    "        continue\n",
    "    \n",
    "    # Create Node Features\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        x.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        x.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        x.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        x.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        x.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        x.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        x.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        x.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        xs.append(x)\n",
    "    x = torch.tensor(xs, dtype=torch.float).view(-1, 9)\n",
    "    \n",
    "    # Create Edge Features\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    # Sort indices.\n",
    "    if edge_index.numel() > 0:\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    x_feat = line.drop(['MOFname', 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]', 'Smiles']).values.astype(float) #, 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]'\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "    \n",
    "    vec = np.expand_dims(mol2vec[idx], axis=0)\n",
    "    vec = torch.tensor(vec)\n",
    "    \n",
    "    x_feat = torch.cat((x_feat, vec), dim=1)\n",
    "    \n",
    "    y=torch.tensor([line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    \n",
    "    data_d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=line['Smiles'], mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "    data_d.num_nodes = len(mol.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_vec.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 55125\n",
      "Number of test graphs: 10500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.16, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "data_loader = DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.conv4 = SAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f8e2a6a-ba42-4c4a-8de0-bf276fd3976b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.gine = GINE(in_xs, in_attr, dim, 128)\n",
    "        self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "        self.bn = BatchNorm1d(256)\n",
    "        self.lin = Sequential(Linear(256, 128), BatchNorm1d(128))\n",
    "        self.lin2 = Sequential(Linear(128, 128), BatchNorm1d(128))\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(128)\n",
    "        self.mlp_cross = MLP(128, 256, 128)\n",
    "        \n",
    "        self.bn_cat = BatchNorm1d(256)\n",
    "        self.mlp_cat = MLP(256, 256, 128)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(128, out_channels) # 256\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, x_feat):\n",
    "        x = self.gine(x, edge_index, edge_attr, batch)\n",
    "        x_feat = self.mlp_num(x_feat)\n",
    "        concat = torch.cat((x, x_feat),dim=1)\n",
    "        x = self.bn(concat)\n",
    "        x = self.lin(x)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "        xl = self.crossnet(x)\n",
    "        x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn_cat(x)\n",
    "        x = self.mlp_cat(x)\n",
    "        x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00365a0-505e-4adf-b703-f17774e8e674",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.gin = GCN(in_xs, dim, 128)\n",
    "        self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "        self.bn = BatchNorm1d(256)\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(256, layer_num=2)\n",
    "        self.mlp_cross = MLP(256, 256, 256)\n",
    "        \n",
    "        self.bn_cat = BatchNorm1d(256) #64+in_xfeats\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.gin(x, edge_index, batch)\n",
    "        x_feat = self.mlp_num(x_feat)\n",
    "        concat = torch.cat((x, x_feat),dim=1)\n",
    "        x = self.bn(concat)\n",
    "        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn_cat(hl)\n",
    "        x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a339c47-6c9b-408d-82ee-77e1efefdebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DCN, self).__init__()\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(in_channels)\n",
    "        self.mlp_cross = MLP(in_channels, 256, 128)\n",
    "        \n",
    "        self.bn = BatchNorm1d(128+in_channels)\n",
    "        self.mlp_cat = MLP(128+in_channels, 512, 256)\n",
    "        self.bn_out = BatchNorm1d(256)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "    def forward(self, x):        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "        xl = self.crossnet(x)\n",
    "        x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.mlp_cat(x)\n",
    "        x = self.bn_out(x)\n",
    "#         x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.g = SAGE(in_xs, dim, 128)\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(256, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.g(x, edge_index, batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        concat = torch.cat((x, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        correct += loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 21\n",
    "num_feats = 321\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 44.1610, Test MAE: 29.3457\n",
      "Epoch: 002, Train MAE: 30.4387, Test MAE: 35.3641\n",
      "Epoch: 003, Train MAE: 28.7000, Test MAE: 26.2649\n",
      "Epoch: 004, Train MAE: 27.6470, Test MAE: 26.4646\n",
      "Epoch: 005, Train MAE: 27.0642, Test MAE: 24.5348\n",
      "Epoch: 006, Train MAE: 26.1248, Test MAE: 24.3394\n",
      "Epoch: 007, Train MAE: 25.9364, Test MAE: 24.3377\n",
      "Epoch: 008, Train MAE: 25.5808, Test MAE: 24.5754\n",
      "Epoch: 009, Train MAE: 25.5274, Test MAE: 22.8885\n",
      "Epoch: 010, Train MAE: 25.0557, Test MAE: 22.7394\n",
      "Epoch: 011, Train MAE: 25.0952, Test MAE: 23.8920\n",
      "Epoch: 012, Train MAE: 24.8928, Test MAE: 22.9974\n",
      "Epoch: 013, Train MAE: 24.3934, Test MAE: 22.2690\n",
      "Epoch: 014, Train MAE: 24.2720, Test MAE: 23.3719\n",
      "Epoch: 015, Train MAE: 24.2480, Test MAE: 22.5945\n",
      "Epoch: 016, Train MAE: 24.0793, Test MAE: 24.1015\n",
      "Epoch: 017, Train MAE: 23.9490, Test MAE: 23.0021\n",
      "Epoch: 018, Train MAE: 23.5860, Test MAE: 21.2487\n",
      "Epoch: 019, Train MAE: 24.0549, Test MAE: 22.1099\n",
      "Epoch: 020, Train MAE: 23.6940, Test MAE: 21.8141\n",
      "Epoch: 021, Train MAE: 23.5925, Test MAE: 21.0323\n",
      "Epoch: 022, Train MAE: 23.1864, Test MAE: 21.9601\n",
      "Epoch: 023, Train MAE: 23.3826, Test MAE: 21.4031\n",
      "Epoch: 024, Train MAE: 23.0347, Test MAE: 20.9832\n",
      "Epoch: 025, Train MAE: 22.9632, Test MAE: 21.4154\n",
      "Epoch: 026, Train MAE: 23.3643, Test MAE: 20.9567\n",
      "Epoch: 027, Train MAE: 23.1713, Test MAE: 20.5681\n",
      "Epoch: 028, Train MAE: 23.1708, Test MAE: 20.3161\n",
      "Epoch: 029, Train MAE: 23.0362, Test MAE: 20.7978\n",
      "Epoch: 030, Train MAE: 22.7619, Test MAE: 21.5504\n",
      "Epoch: 031, Train MAE: 22.7626, Test MAE: 20.9552\n",
      "Epoch: 032, Train MAE: 22.9750, Test MAE: 20.8215\n",
      "Epoch: 033, Train MAE: 22.6533, Test MAE: 20.7243\n",
      "Epoch: 034, Train MAE: 22.5545, Test MAE: 20.7417\n",
      "Epoch: 035, Train MAE: 22.3489, Test MAE: 21.0540\n",
      "Epoch: 036, Train MAE: 22.5166, Test MAE: 21.9398\n",
      "Epoch: 037, Train MAE: 22.2148, Test MAE: 20.1144\n",
      "Epoch: 038, Train MAE: 22.1371, Test MAE: 20.2703\n",
      "Epoch: 039, Train MAE: 22.0968, Test MAE: 21.8016\n",
      "Epoch: 040, Train MAE: 22.0137, Test MAE: 20.7463\n",
      "Epoch: 041, Train MAE: 21.8750, Test MAE: 20.6767\n",
      "Epoch: 042, Train MAE: 21.8814, Test MAE: 20.1143\n",
      "Epoch: 043, Train MAE: 21.7988, Test MAE: 21.2411\n",
      "Epoch: 044, Train MAE: 21.8956, Test MAE: 20.3281\n",
      "Epoch: 045, Train MAE: 21.9243, Test MAE: 19.9792\n",
      "Epoch: 046, Train MAE: 21.8488, Test MAE: 20.7911\n",
      "Epoch: 047, Train MAE: 21.7581, Test MAE: 20.7157\n",
      "Epoch: 048, Train MAE: 21.6837, Test MAE: 20.1812\n",
      "Epoch: 049, Train MAE: 21.6436, Test MAE: 20.9309\n",
      "Epoch: 050, Train MAE: 21.5344, Test MAE: 20.2382\n",
      "Epoch: 051, Train MAE: 21.3147, Test MAE: 20.0342\n",
      "Epoch: 052, Train MAE: 21.5030, Test MAE: 19.8105\n",
      "Epoch: 053, Train MAE: 21.4818, Test MAE: 19.7409\n",
      "Epoch: 054, Train MAE: 21.3047, Test MAE: 19.9612\n",
      "Epoch: 055, Train MAE: 21.3392, Test MAE: 20.3963\n",
      "Epoch: 056, Train MAE: 21.3160, Test MAE: 19.8484\n",
      "Epoch: 057, Train MAE: 21.5133, Test MAE: 20.6485\n",
      "Epoch: 058, Train MAE: 21.3181, Test MAE: 19.7907\n",
      "Epoch: 059, Train MAE: 21.1154, Test MAE: 19.7990\n",
      "Epoch: 060, Train MAE: 21.1412, Test MAE: 19.7536\n",
      "Epoch: 061, Train MAE: 21.1278, Test MAE: 21.1888\n",
      "Epoch: 062, Train MAE: 21.1405, Test MAE: 19.9116\n",
      "Epoch: 063, Train MAE: 20.9977, Test MAE: 19.7961\n",
      "Epoch: 064, Train MAE: 20.8272, Test MAE: 20.0757\n",
      "Epoch: 065, Train MAE: 20.9586, Test MAE: 19.8015\n",
      "Epoch: 066, Train MAE: 20.7797, Test MAE: 19.6716\n",
      "Epoch: 067, Train MAE: 20.8576, Test MAE: 19.5627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/3879099282.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/2158525453.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Iterate in batches over the training dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Perform a single forward pass. , data.edge_attr.float()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Compute the loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/2935646323.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, batch, x_feat)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mcross\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mmlp_cross\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp_cross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mconcat2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlp_cross\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/1736698989.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mxl_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mdot_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxl_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx_l\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mtensordot\u001b[1;34m(a, b, dims, out)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_numGNN2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65625\n",
      "Number of test graphs: 16237\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19612b6d-768d-47f0-be2d-b95967d97150",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "382f0082-062f-42cb-a1b4-4b22409384eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392a1c4-045e-4f56-9717-7c64816f1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out)\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>195.468613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>69.653137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>66.580437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>55.399101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>64.502907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-6.392035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.936134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>0.404633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-1.013318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-4.414718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   195.468613\n",
       "1      68615                    69.653137\n",
       "2      68616                    66.580437\n",
       "3      68617                    55.399101\n",
       "4      68618                    64.502907\n",
       "...      ...                          ...\n",
       "16995  85609                    -6.392035\n",
       "16996  85610                     1.936134\n",
       "16997  85611                     0.404633\n",
       "16998  85612                    -1.013318\n",
       "16999  85613                    -4.414718\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c6873-c420-4661-a9d2-aaf9dabfca55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

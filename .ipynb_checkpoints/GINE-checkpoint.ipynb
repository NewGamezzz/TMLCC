{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a450026a-e193-427c-93f2-bc08eff7e133",
   "metadata": {
    "id": "a450026a-e193-427c-93f2-bc08eff7e133"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae04383-8d79-4413-a02d-9abb8253f376",
   "metadata": {},
   "source": [
    "# Run on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ad607d-16fb-4037-ab2f-afb220f9c51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeff4fd-6b02-4ea6-8865-1b4f54c99761",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eba9b374-fdd8-44d3-ac51-13f36215ac5d",
   "metadata": {
    "id": "eba9b374-fdd8-44d3-ac51-13f36215ac5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOFname                                             0\n",
      "volume [A^3]                                        0\n",
      "weight [u]                                          0\n",
      "surface_area [m^2/g]                                0\n",
      "void_fraction                                       0\n",
      "void_volume [cm^3/g]                                0\n",
      "functional_groups                                 323\n",
      "metal_linker                                        0\n",
      "organic_linker1                                     0\n",
      "organic_linker2                                     0\n",
      "topology                                            0\n",
      "CO2/N2_selectivity                                  0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    2087\n",
      "CO2_working_capacity [mL/g]                         0\n",
      "Smiles                                              0\n",
      "dtype: int64\n",
      "(68611, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/train.csv')\n",
    "smiles = pd.read_csv('data/train/smiles_train.csv')\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b426ccc-42e3-4d43-a268-3772bbe2f93c",
   "metadata": {
    "id": "3b426ccc-42e3-4d43-a268-3772bbe2f93c"
   },
   "outputs": [],
   "source": [
    "x_map = {\n",
    "    'atomic_num':\n",
    "    list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED',\n",
    "        'CHI_TETRAHEDRAL_CW',\n",
    "        'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER',\n",
    "    ],\n",
    "    'degree':\n",
    "    list(range(0, 11)),\n",
    "    'formal_charge':\n",
    "    list(range(-5, 7)),\n",
    "    'num_hs':\n",
    "    list(range(0, 9)),\n",
    "    'num_radical_electrons':\n",
    "    list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED',\n",
    "        'S',\n",
    "        'SP',\n",
    "        'SP2',\n",
    "        'SP3',\n",
    "        'SP3D',\n",
    "        'SP3D2',\n",
    "        'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "}\n",
    "\n",
    "e_map = {\n",
    "    'bond_type': [\n",
    "        'misc',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'AROMATIC',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "        'STEREOANY',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c2d2a-e57a-40c5-933a-ae2f925ce2f1",
   "metadata": {
    "id": "f67c2d2a-e57a-40c5-933a-ae2f925ce2f1",
    "outputId": "4dbf6c82-8af0-4ea0-9a2e-48054794ca79"
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "c = 1\n",
    "for _, line in data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(line['Smiles'])\n",
    "    \n",
    "    if mol == None:\n",
    "        continue\n",
    "    \n",
    "    # Create Node Features\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        x.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        x.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        x.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        x.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        x.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        x.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        x.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        x.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        xs.append(x)\n",
    "    x = torch.tensor(xs, dtype=torch.float).view(-1, 9)\n",
    "    \n",
    "    # Create Edge Features\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    # Sort indices.\n",
    "    if edge_index.numel() > 0:\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    y=torch.tensor([line['CO2/N2_selectivity'], line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    data_d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y,smiles=line['Smiles'])\n",
    "    data_d.num_nodes = len(mol.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ca19d13-84be-483c-a4b0-e3eb9c137e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_list = False\n",
    "if save_data_list:\n",
    "    pickle.dump(data_list, open('', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d01a7909-60cf-407b-b4a2-f56621d7546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_list = pickle.load(open('data/train/graph_train_2_loss.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027cea3-997b-46ad-90b6-902947cdbb29",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "395a99a3-4e96-437c-a113-ac27e1835a97",
   "metadata": {
    "id": "395a99a3-4e96-437c-a113-ac27e1835a97",
    "outputId": "94a9a6af-e87c-4b4f-de14-d25c5a1aa44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 49218\n",
      "Number of test graphs: 16407\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(12345)\n",
    "#dataset = dataset.shuffle()\n",
    "\n",
    "#num_train=int(0.8*len(data_list))\n",
    "#num_test=len(data_list)-num_train\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.25, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d94a9d4-c4eb-4f54-b262-a742197c39d2",
   "metadata": {
    "id": "1d94a9d4-c4eb-4f54-b262-a742197c39d2"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "data_loader = DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c43d9-a425-4aa6-a027-5c64f6765cf9",
   "metadata": {},
   "source": [
    "# GIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed74dc3b-82f5-4888-8fb8-9a289e574589",
   "metadata": {
    "id": "ed74dc3b-82f5-4888-8fb8-9a289e574589"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GINConv, GINEConv, global_add_pool\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e741ed0-26ab-4581-8c9b-304227070f56",
   "metadata": {
    "id": "3e741ed0-26ab-4581-8c9b-304227070f56"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.attr1 = Linear(in_attr, in_channels)\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Linear(in_channels, dim)\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Linear(dim, dim)\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Linear(dim, dim)\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Linear(dim, dim)\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "    \n",
    "    def latent_space(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f093a444-645c-49eb-9fce-1e659c768b87",
   "metadata": {
    "id": "f093a444-645c-49eb-9fce-1e659c768b87",
    "outputId": "d02d0ba3-f45b-4675-b4af-e850c122e164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (attr1): Linear(in_features=3, out_features=9, bias=True)\n",
      "  (conv1): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=9, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (attr2): Linear(in_features=9, out_features=256, bias=True)\n",
      "  (conv2): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (attr3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (conv3): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (attr4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (conv4): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (attr5): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (conv5): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (lin2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn.models import GIN\n",
    "\n",
    "num_node_features = 9\n",
    "hidden_channels = 256\n",
    "num_classes = 2\n",
    "num_attr_features = 3\n",
    "\n",
    "model = Net(in_channels=num_node_features, in_attr = num_attr_features, dim=hidden_channels,out_channels=num_classes).to(device)#GCN(hidden_channels=64,num_node_features=9,num_classes=1)\n",
    "# model.load_state_dict(torch.load('model/best-model-GIN_Jack.pt')) # Load Model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd42a28-5ec8-4e6b-a604-027e8349527f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8bf00f7-aced-44c8-ad0c-3eb10de7ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a755e2e6-4cb0-4e32-8462-82bda35c1c93",
   "metadata": {
    "id": "a755e2e6-4cb0-4e32-8462-82bda35c1c93",
    "outputId": "902b549c-e323-427d-ea65-57d48ca4438e"
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        model.eval()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr.float(), data.batch)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss_target = criterion(out[:, 1], data.y[:, 1]).cpu().detach().numpy()\n",
    "        \n",
    "        scaler.scale(loss).backward()  # Derive gradients.\n",
    "        scaler.step(optimizer)  # Update parameters based on gradients.\n",
    "        scaler.update()  # Clear gradients.\n",
    "        \n",
    "#         print('done:',c+1,'batch','loss:',loss)\n",
    "        c=c+1\n",
    "        correct+=loss_target\n",
    "        torch.cuda.empty_cache()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr.float(), data.batch)  \n",
    "        loss = criterion(out[:, 1], data.y[:, 1])  # Compute the loss.\n",
    "        correct += loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "        torch.cuda.empty_cache()\n",
    "        loss.cpu().detach().numpy()\n",
    "        #print(correct)\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55716d38-2990-4729-b0dc-9aefdbc98aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 73.8897, Test MAE: 68.8739\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1936/1188068820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1936/4285788091.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Derive gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Update parameters based on gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Clear gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('start train')\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(data_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')\n",
    "#     print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e947fbc-9282-48ca-bc5f-646d27d1fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2a4c2623-d5a2-400a-97d7-d518937f6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/best_GIN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c88c6-e318-44c2-9c69-cca856407ff7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d106055c-2a2c-4c5a-be33-8b09fb99f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/test/graph_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6ea16a92-8fcd-4fd8-9fb7-44cf8445b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(data_list, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c28f906-b107-4018-ab45-ec10bd265202",
   "metadata": {
    "id": "0c28f906-b107-4018-ab45-ec10bd265202",
    "outputId": "10c2192e-0c8a-4892-b38b-ca178218708e"
   },
   "outputs": [],
   "source": [
    "latent_space_list = []\n",
    "\n",
    "for data in data_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    latent_space = model.latent_space(data.x, data.edge_index, data.batch).cpu().detach().numpy()\n",
    "    latent_space_list.append(latent_space)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "latent_space_list = np.concatenate(latent_space_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2f9fbf3b-1a80-4fd8-8879-d62134652bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16237, 256)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_space_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d5dcfab1-c430-46b2-9e04-d071787c3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(latent_space_list, open('data/test/latent_space.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1f0da-a754-469e-ae7a-f524982cf99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pytorch_geotric.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

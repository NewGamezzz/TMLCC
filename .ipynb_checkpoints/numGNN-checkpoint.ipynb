{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, GraphConv, SAGEConv, ChebConv, SAGPooling, global_add_pool, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.utils import generate_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "MOFname                                          0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "CO2_working_capacity [mL/g]                      0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(68611, 26)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/clean_train_edited.csv')\n",
    "smiles = pd.read_csv('data/train/smiles_train.csv')\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11f0e34-b17a-4f43-9a1a-0b4f0d2fc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = {\n",
    "    'atomic_num':\n",
    "    list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED',\n",
    "        'CHI_TETRAHEDRAL_CW',\n",
    "        'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER',\n",
    "    ],\n",
    "    'degree':\n",
    "    list(range(0, 11)),\n",
    "    'formal_charge':\n",
    "    list(range(-5, 7)),\n",
    "    'num_hs':\n",
    "    list(range(0, 9)),\n",
    "    'num_radical_electrons':\n",
    "    list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED',\n",
    "        'S',\n",
    "        'SP',\n",
    "        'SP2',\n",
    "        'SP3',\n",
    "        'SP3D',\n",
    "        'SP3D2',\n",
    "        'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "}\n",
    "\n",
    "e_map = {\n",
    "    'bond_type': [\n",
    "        'misc',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'AROMATIC',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "        'STEREOANY',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n",
      "done: 20000\n",
      "done: 30000\n",
      "done: 40000\n",
      "done: 50000\n",
      "done: 60000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "c = 1\n",
    "for _, line in data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(line['Smiles'])\n",
    "    \n",
    "    if mol == None:\n",
    "        continue\n",
    "    \n",
    "    # Create Node Features\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        x.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        x.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        x.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        x.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        x.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        x.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        x.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        x.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        xs.append(x)\n",
    "    x = torch.tensor(xs, dtype=torch.float).view(-1, 9)\n",
    "    \n",
    "    # Create Edge Features\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    # Sort indices.\n",
    "    if edge_index.numel() > 0:\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    x_feat = line.drop(['MOFname', 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]', 'Smiles']).values.astype(float) #, 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]'\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "    y=torch.tensor([line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    data_d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=line['Smiles'], mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "    data_d.num_nodes = len(mol.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_concat.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 55125\n",
      "Number of test graphs: 10500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.16, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "data_loader = DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.conv4 = SAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "076a8ea7-489f-4c71-a2fa-dff23f7b485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEHP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(SAGEHP, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.pool1 = SAGPooling(dim, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.pool2 = SAGPooling(dim, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.pool3 = SAGPooling(dim, ratio=0.8)\n",
    "        self.conv4 = SAGEConv(dim, dim)\n",
    "        self.pool4 = SAGPooling(dim, ratio=0.8)\n",
    "        self.lin = Linear(dim*2, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        \n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        \n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        \n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x, edge_index, _, batch, _, _ = self.pool4(x, edge_index, None, batch)\n",
    "        x4 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        \n",
    "        x = x2 + x3 + x4\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ffba7f3-45e4-495d-a44d-8c9bd2fb90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(Graph, self).__init__()\n",
    "        self.conv1 = GraphConv(in_channels, dim)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.conv3 = GraphConv(dim, dim)\n",
    "        self.conv4 = GraphConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f8e2a6a-ba42-4c4a-8de0-bf276fd3976b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.gine = GINE(in_xs, in_attr, dim, 128)\n",
    "#         self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "#         self.bn = BatchNorm1d(256)\n",
    "#         self.lin = Sequential(Linear(256, 128), BatchNorm1d(128))\n",
    "#         self.lin2 = Sequential(Linear(128, 128), BatchNorm1d(128))\n",
    "#         # Deep & Cross Network\n",
    "#         self.crossnet = CrossNet(128)\n",
    "#         self.mlp_cross = MLP(128, 256, 128)\n",
    "        \n",
    "#         self.bn_cat = BatchNorm1d(256)\n",
    "#         self.mlp_cat = MLP(256, 256, 128)\n",
    "#         self.dropout = Dropout(p=0.5)\n",
    "#         self.out = Linear(128, out_channels) # 256\n",
    "\n",
    "#     def forward(self, x, edge_index, edge_attr, batch, x_feat):\n",
    "#         x = self.gine(x, edge_index, edge_attr, batch)\n",
    "#         x_feat = self.mlp_num(x_feat)\n",
    "#         concat = torch.cat((x, x_feat),dim=1)\n",
    "#         x = self.bn(concat)\n",
    "#         x = self.lin(x)\n",
    "#         x = self.lin2(x)\n",
    "        \n",
    "#         # Deep & Cross Network\n",
    "#         hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "#         x = self.bn_cat(x)\n",
    "#         x = self.mlp_cat(x)\n",
    "#         x = self.dropout(x)\n",
    "#         out = self.out(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d00365a0-505e-4adf-b703-f17774e8e674",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.gin = GCN(in_xs, dim, 128)\n",
    "#         self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "#         self.bn = BatchNorm1d(256)\n",
    "#         # Deep & Cross Network\n",
    "#         self.crossnet = CrossNet(256, layer_num=2)\n",
    "#         self.mlp_cross = MLP(256, 256, 256)\n",
    "        \n",
    "#         self.bn_cat = BatchNorm1d(256) #64+in_xfeats\n",
    "#         self.dropout = Dropout(p=0.5)\n",
    "#         self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "#     def forward(self, x, edge_index, batch, x_feat):\n",
    "#         x = self.gin(x, edge_index, batch)\n",
    "#         x_feat = self.mlp_num(x_feat)\n",
    "#         concat = torch.cat((x, x_feat),dim=1)\n",
    "#         x = self.bn(concat)\n",
    "        \n",
    "#         # Deep & Cross Network\n",
    "#         hl = self.mlp_cross(x)\n",
    "# #         xl = self.crossnet(x)\n",
    "# #         x = torch.cat((xl, hl), dim=1)\n",
    "#         x = self.bn_cat(hl)\n",
    "#         x = self.dropout(x)\n",
    "#         out = self.out(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a339c47-6c9b-408d-82ee-77e1efefdebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class DCN(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DCN, self).__init__()\n",
    "#         # Deep & Cross Network\n",
    "#         self.crossnet = CrossNet(in_channels)\n",
    "#         self.mlp_cross = MLP(in_channels, 256, 128)\n",
    "        \n",
    "#         self.bn = BatchNorm1d(128+in_channels)\n",
    "#         self.mlp_cat = MLP(128+in_channels, 512, 256)\n",
    "#         self.bn_out = BatchNorm1d(256)\n",
    "#         self.dropout = Dropout(p=0.5)\n",
    "#         self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "#     def forward(self, x):        \n",
    "#         # Deep & Cross Network\n",
    "#         hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.mlp_cat(x)\n",
    "#         x = self.bn_out(x)\n",
    "# #         x = self.dropout(x)\n",
    "#         out = self.out(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.g = SAGEHP(in_xs, dim, 128) # SAGE\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(256, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.g(x, edge_index, batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        concat = torch.cat((x, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        correct += loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 64 # SAGE: 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001) #factor=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 38.2950, Test MAE: 24.8181\n",
      "Epoch: 002, Train MAE: 26.2166, Test MAE: 25.5509\n",
      "Epoch: 003, Train MAE: 24.4778, Test MAE: 22.2345\n",
      "Epoch: 004, Train MAE: 23.8731, Test MAE: 22.6548\n",
      "Epoch: 005, Train MAE: 23.3993, Test MAE: 21.3244\n",
      "Epoch: 006, Train MAE: 23.3232, Test MAE: 21.7249\n",
      "Epoch: 007, Train MAE: 22.6347, Test MAE: 21.0786\n",
      "Epoch: 008, Train MAE: 22.6281, Test MAE: 21.3390\n",
      "Epoch: 009, Train MAE: 22.0837, Test MAE: 24.0697\n",
      "Epoch: 010, Train MAE: 22.0191, Test MAE: 22.5267\n",
      "Epoch: 011, Train MAE: 21.9446, Test MAE: 20.4270\n",
      "Epoch: 012, Train MAE: 21.7741, Test MAE: 20.5988\n",
      "Epoch: 013, Train MAE: 21.6595, Test MAE: 20.8628\n",
      "Epoch: 014, Train MAE: 21.4537, Test MAE: 20.9217\n",
      "Epoch: 015, Train MAE: 21.4372, Test MAE: 20.5126\n",
      "Epoch: 016, Train MAE: 21.2446, Test MAE: 20.3886\n",
      "Epoch: 017, Train MAE: 20.9087, Test MAE: 19.8668\n",
      "Epoch: 018, Train MAE: 21.0030, Test MAE: 19.7306\n",
      "Epoch: 019, Train MAE: 20.8438, Test MAE: 20.2575\n",
      "Epoch: 020, Train MAE: 20.8223, Test MAE: 20.3925\n",
      "Epoch: 021, Train MAE: 20.6841, Test MAE: 20.5533\n",
      "Epoch: 022, Train MAE: 20.8997, Test MAE: 20.1827\n",
      "Epoch: 023, Train MAE: 20.4353, Test MAE: 20.0330\n",
      "Epoch: 024, Train MAE: 20.4078, Test MAE: 19.6098\n",
      "Epoch: 025, Train MAE: 20.3698, Test MAE: 19.8246\n",
      "Epoch: 026, Train MAE: 20.3001, Test MAE: 19.7003\n",
      "Epoch: 027, Train MAE: 20.2215, Test MAE: 20.5080\n",
      "Epoch: 028, Train MAE: 20.1953, Test MAE: 19.8282\n",
      "Epoch: 029, Train MAE: 19.9056, Test MAE: 20.1780\n",
      "Epoch: 030, Train MAE: 19.9360, Test MAE: 19.7986\n",
      "Epoch: 031, Train MAE: 19.8735, Test MAE: 19.4004\n",
      "Epoch: 032, Train MAE: 19.8782, Test MAE: 19.6522\n",
      "Epoch: 033, Train MAE: 19.9583, Test MAE: 20.2399\n",
      "Epoch: 034, Train MAE: 19.8192, Test MAE: 19.9082\n",
      "Epoch: 035, Train MAE: 19.8052, Test MAE: 20.7636\n",
      "Epoch: 036, Train MAE: 19.6299, Test MAE: 19.2450\n",
      "Epoch: 037, Train MAE: 19.5726, Test MAE: 19.2139\n",
      "Epoch: 038, Train MAE: 19.5018, Test MAE: 19.3599\n",
      "Epoch: 039, Train MAE: 19.3636, Test MAE: 19.6939\n",
      "Epoch: 040, Train MAE: 19.3853, Test MAE: 19.1522\n",
      "Epoch: 041, Train MAE: 19.4904, Test MAE: 19.1224\n",
      "Epoch: 042, Train MAE: 30.8250, Test MAE: 19.9464\n",
      "Epoch: 043, Train MAE: 19.8074, Test MAE: 19.0844\n",
      "Epoch: 044, Train MAE: 19.4426, Test MAE: 19.2137\n",
      "Epoch: 045, Train MAE: 19.3860, Test MAE: 19.4327\n",
      "Epoch: 046, Train MAE: 19.2986, Test MAE: 19.5009\n",
      "Epoch: 047, Train MAE: 19.2503, Test MAE: 19.4644\n",
      "Epoch: 048, Train MAE: 19.1225, Test MAE: 19.4836\n",
      "Epoch: 049, Train MAE: 19.0518, Test MAE: 19.2334\n",
      "Epoch: 050, Train MAE: 19.1810, Test MAE: 19.1429\n",
      "Epoch: 051, Train MAE: 19.1439, Test MAE: 19.1115\n",
      "Epoch: 052, Train MAE: 18.8626, Test MAE: 18.9917\n",
      "Epoch: 053, Train MAE: 18.8599, Test MAE: 19.1473\n",
      "Epoch: 054, Train MAE: 18.7885, Test MAE: 19.4801\n",
      "Epoch: 055, Train MAE: 18.7830, Test MAE: 19.0516\n",
      "Epoch: 056, Train MAE: 18.8407, Test MAE: 18.9508\n",
      "Epoch: 057, Train MAE: 18.8064, Test MAE: 19.0985\n",
      "Epoch: 058, Train MAE: 18.9009, Test MAE: 19.0246\n",
      "Epoch: 059, Train MAE: 18.7903, Test MAE: 18.9056\n",
      "Epoch: 060, Train MAE: 18.7801, Test MAE: 19.1956\n",
      "Epoch: 061, Train MAE: 18.7918, Test MAE: 19.0400\n",
      "Epoch: 062, Train MAE: 18.7301, Test MAE: 18.9347\n",
      "Epoch: 063, Train MAE: 18.7823, Test MAE: 19.0734\n",
      "Epoch: 064, Train MAE: 18.4948, Test MAE: 18.9608\n",
      "Epoch: 065, Train MAE: 18.5425, Test MAE: 18.9876\n",
      "Epoch: 066, Train MAE: 18.5058, Test MAE: 19.0342\n",
      "Epoch: 067, Train MAE: 18.6198, Test MAE: 19.0419\n",
      "Epoch: 068, Train MAE: 18.3837, Test MAE: 18.8934\n",
      "Epoch: 069, Train MAE: 18.3213, Test MAE: 18.8611\n",
      "Epoch: 070, Train MAE: 18.4262, Test MAE: 19.0557\n",
      "Epoch: 071, Train MAE: 18.4906, Test MAE: 19.1950\n",
      "Epoch: 072, Train MAE: 18.3604, Test MAE: 18.8882\n",
      "Epoch: 073, Train MAE: 18.3232, Test MAE: 18.9156\n",
      "Epoch: 074, Train MAE: 18.2228, Test MAE: 18.8313\n",
      "Epoch: 075, Train MAE: 18.2054, Test MAE: 18.8475\n",
      "Epoch: 076, Train MAE: 18.1782, Test MAE: 18.9156\n",
      "Epoch: 077, Train MAE: 18.1403, Test MAE: 18.7325\n",
      "Epoch: 078, Train MAE: 18.1648, Test MAE: 18.9356\n",
      "Epoch: 079, Train MAE: 18.0986, Test MAE: 18.8507\n",
      "Epoch: 080, Train MAE: 18.1390, Test MAE: 18.9090\n",
      "Epoch: 081, Train MAE: 18.1208, Test MAE: 18.9105\n",
      "Epoch: 082, Train MAE: 17.9239, Test MAE: 18.8882\n",
      "Epoch: 083, Train MAE: 17.9850, Test MAE: 19.1927\n",
      "Epoch: 084, Train MAE: 17.9352, Test MAE: 18.8556\n",
      "Epoch: 085, Train MAE: 17.9943, Test MAE: 18.9137\n",
      "Epoch: 086, Train MAE: 17.8457, Test MAE: 18.8912\n",
      "Epoch: 087, Train MAE: 17.8619, Test MAE: 18.7437\n",
      "Epoch: 088, Train MAE: 17.8030, Test MAE: 18.7994\n",
      "Epoch: 089, Train MAE: 17.7894, Test MAE: 18.8489\n",
      "Epoch: 090, Train MAE: 17.7359, Test MAE: 19.0895\n",
      "Epoch: 091, Train MAE: 17.6855, Test MAE: 18.9701\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_numGNN2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65625\n",
      "Number of test graphs: 16237\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2ece4-05e7-469a-a880-0eb27fe99531",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "160f8d28-db63-4202-ab0f-64e030d9b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=21, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)\n",
    "\n",
    "model.load_state_dict(torch.load('model/best_SAGE_concat.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out)\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>216.854218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>71.110825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>63.646053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>55.750607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>65.396301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-7.181580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.273886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>-0.719142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-1.186282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-4.660836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   216.854218\n",
       "1      68615                    71.110825\n",
       "2      68616                    63.646053\n",
       "3      68617                    55.750607\n",
       "4      68618                    65.396301\n",
       "...      ...                          ...\n",
       "16995  85609                    -7.181580\n",
       "16996  85610                     1.273886\n",
       "16997  85611                    -0.719142\n",
       "16998  85612                    -1.186282\n",
       "16999  85613                    -4.660836\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfd22f-5ebe-43cd-9621-06a0ddcd6f37",
   "metadata": {},
   "source": [
    "## Create Latent Space for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3da5e7a7-88cc-46b5-a7e5-2aca58e7215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=21, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out=nn.Sequential(*list(model.out.children())[:-1])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91628a15-bd6f-4df6-812e-d86634bc8e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n",
      "done: 200\n",
      "done: 300\n",
      "done: 400\n",
      "done: 500\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "train_x = []\n",
    "train_y = []\n",
    "train_mofname = []\n",
    "\n",
    "for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    train_x.append(out)\n",
    "    train_y.append(data.y.cpu().detach().numpy())\n",
    "    train_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "train_x = np.concatenate(train_x, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "train_mofname = np.concatenate(train_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00dc8e64-9c19-401b-864d-13b4539fa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "test_x = []\n",
    "test_mofname = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    test_x.append(out)\n",
    "    test_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "test_x = np.concatenate(test_x, axis=0)\n",
    "test_mofname = np.concatenate(test_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8b951cd-46fd-4d9a-b530-cdf6e6cfc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_x)\n",
    "test_df = pd.DataFrame(test_x)\n",
    "\n",
    "train_df['target'] = train_y.flatten()\n",
    "train_df['mofname'] = train_mofname.flatten()\n",
    "test_df['mofname'] = test_mofname.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30c2f8-7470-484a-853b-d5d47037c187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65625,), (65625,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mofname.shape, co2_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cf83f50-e2a7-4ab8-8c32-aec32212f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'mofname': mofname, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59a166-f0e8-438e-95fb-49c5fa3af489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train/Latent_SAGE_feat_train.csv',index=False)\n",
    "# test_df.to_csv('data/test/Latent_SAGE_feat_mofname_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12171eea-b02a-49f7-b95d-493d132fec69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mofname</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mof_unit_1</td>\n",
       "      <td>89.982483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mof_unit_2</td>\n",
       "      <td>95.660843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mof_unit_4</td>\n",
       "      <td>160.562881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mof_unit_5</td>\n",
       "      <td>88.837372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mof_unit_6</td>\n",
       "      <td>66.148277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65620</th>\n",
       "      <td>mof_unit_68609</td>\n",
       "      <td>10.749875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65621</th>\n",
       "      <td>mof_unit_68610</td>\n",
       "      <td>0.032699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65622</th>\n",
       "      <td>mof_unit_68611</td>\n",
       "      <td>0.301270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65623</th>\n",
       "      <td>mof_unit_68612</td>\n",
       "      <td>0.037428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65624</th>\n",
       "      <td>mof_unit_68613</td>\n",
       "      <td>0.024978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65625 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mofname     predict\n",
       "0          mof_unit_1   89.982483\n",
       "1          mof_unit_2   95.660843\n",
       "2          mof_unit_4  160.562881\n",
       "3          mof_unit_5   88.837372\n",
       "4          mof_unit_6   66.148277\n",
       "...               ...         ...\n",
       "65620  mof_unit_68609   10.749875\n",
       "65621  mof_unit_68610    0.032699\n",
       "65622  mof_unit_68611    0.301270\n",
       "65623  mof_unit_68612    0.037428\n",
       "65624  mof_unit_68613    0.024978\n",
       "\n",
       "[65625 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99189d-4947-4149-8e7b-9b48a564f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.join(smiles.set_index('MOFname'), on='MOFname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444203d4-0732-4236-b4b7-07da0cd33871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mofname</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>target</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mof_unit_1</td>\n",
       "      <td>13.082182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.234041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.093610</td>\n",
       "      <td>-0.661012</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.703202</td>\n",
       "      <td>-0.921714</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.038235</td>\n",
       "      <td>0.578007</td>\n",
       "      <td>105.284500</td>\n",
       "      <td>89.982483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mof_unit_2</td>\n",
       "      <td>13.931372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.117464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737443</td>\n",
       "      <td>-0.570913</td>\n",
       "      <td>1.806121</td>\n",
       "      <td>2.994665</td>\n",
       "      <td>3.582469</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>0.031265</td>\n",
       "      <td>0.830237</td>\n",
       "      <td>101.224777</td>\n",
       "      <td>95.660843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mof_unit_4</td>\n",
       "      <td>23.637325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.421621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252887</td>\n",
       "      <td>-0.325378</td>\n",
       "      <td>1.491358</td>\n",
       "      <td>0.498605</td>\n",
       "      <td>0.351208</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.019897</td>\n",
       "      <td>0.161896</td>\n",
       "      <td>187.626007</td>\n",
       "      <td>160.562881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mof_unit_5</td>\n",
       "      <td>12.911613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.052068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.100921</td>\n",
       "      <td>-0.664341</td>\n",
       "      <td>-0.711980</td>\n",
       "      <td>-0.980542</td>\n",
       "      <td>0.155374</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.362969</td>\n",
       "      <td>79.209999</td>\n",
       "      <td>88.837372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mof_unit_6</td>\n",
       "      <td>9.515944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.403864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670308</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>1.491358</td>\n",
       "      <td>-0.425862</td>\n",
       "      <td>0.253291</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.075191</td>\n",
       "      <td>-0.390945</td>\n",
       "      <td>55.786961</td>\n",
       "      <td>66.148277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65620</th>\n",
       "      <td>mof_unit_68609</td>\n",
       "      <td>1.574537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.899714</td>\n",
       "      <td>0.337198</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.570856</td>\n",
       "      <td>-0.787317</td>\n",
       "      <td>-0.397217</td>\n",
       "      <td>-0.703202</td>\n",
       "      <td>0.351208</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.030042</td>\n",
       "      <td>0.219719</td>\n",
       "      <td>-12.943652</td>\n",
       "      <td>10.749875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65621</th>\n",
       "      <td>mof_unit_68610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528994</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.503912</td>\n",
       "      <td>-0.787317</td>\n",
       "      <td>1.806121</td>\n",
       "      <td>2.809771</td>\n",
       "      <td>2.505382</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.146773</td>\n",
       "      <td>-1.755135</td>\n",
       "      <td>-12.985581</td>\n",
       "      <td>0.032699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65622</th>\n",
       "      <td>mof_unit_68611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399044</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.570856</td>\n",
       "      <td>-0.787317</td>\n",
       "      <td>-0.082455</td>\n",
       "      <td>0.221265</td>\n",
       "      <td>0.155374</td>\n",
       "      <td>0.359778</td>\n",
       "      <td>-0.122184</td>\n",
       "      <td>0.219719</td>\n",
       "      <td>-13.187635</td>\n",
       "      <td>0.301270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65623</th>\n",
       "      <td>mof_unit_68612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523465</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.570856</td>\n",
       "      <td>-0.787317</td>\n",
       "      <td>-0.082455</td>\n",
       "      <td>-0.703202</td>\n",
       "      <td>-0.530045</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>-1.755135</td>\n",
       "      <td>15.672698</td>\n",
       "      <td>0.037428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65624</th>\n",
       "      <td>mof_unit_68613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.539275</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.473643</td>\n",
       "      <td>-0.787317</td>\n",
       "      <td>-0.711980</td>\n",
       "      <td>-0.240968</td>\n",
       "      <td>-0.432128</td>\n",
       "      <td>-2.779491</td>\n",
       "      <td>-0.169076</td>\n",
       "      <td>-1.755135</td>\n",
       "      <td>3.144708</td>\n",
       "      <td>0.024978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65625 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mofname          0    1    2    3    4    5         6  \\\n",
       "0          mof_unit_1  13.082182  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "1          mof_unit_2  13.931372  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "2          mof_unit_4  23.637325  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "3          mof_unit_5  12.911613  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "4          mof_unit_6   9.515944  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "...               ...        ...  ...  ...  ...  ...  ...       ...   \n",
       "65620  mof_unit_68609   1.574537  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "65621  mof_unit_68610   0.000000  0.0  0.0  0.0  0.0  0.0  0.578905   \n",
       "65622  mof_unit_68611   0.000000  0.0  0.0  0.0  0.0  0.0  0.563143   \n",
       "65623  mof_unit_68612   0.000000  0.0  0.0  0.0  0.0  0.0  0.582178   \n",
       "65624  mof_unit_68613   0.000000  0.0  0.0  0.0  0.0  0.0  0.578771   \n",
       "\n",
       "               7         8  ...       269       270       271       272  \\\n",
       "0      14.234041  0.000000  ... -1.093610 -0.661012 -0.397217 -0.703202   \n",
       "1      15.117464  0.000000  ... -0.737443 -0.570913  1.806121  2.994665   \n",
       "2      25.421621  0.000000  ... -0.252887 -0.325378  1.491358  0.498605   \n",
       "3      14.052068  0.000000  ... -1.100921 -0.664341 -0.711980 -0.980542   \n",
       "4      10.403864  0.000000  ...  0.670308  0.403943  1.491358 -0.425862   \n",
       "...          ...       ...  ...       ...       ...       ...       ...   \n",
       "65620   1.899714  0.337198  ... -1.570856 -0.787317 -0.397217 -0.703202   \n",
       "65621   0.000000  0.528994  ... -1.503912 -0.787317  1.806121  2.809771   \n",
       "65622   0.000000  0.399044  ... -1.570856 -0.787317 -0.082455  0.221265   \n",
       "65623   0.000000  0.523465  ... -1.570856 -0.787317 -0.082455 -0.703202   \n",
       "65624   0.000000  0.539275  ... -1.473643 -0.787317 -0.711980 -0.240968   \n",
       "\n",
       "            273       274       275       276      target     predict  \n",
       "0     -0.921714  0.359778 -0.038235  0.578007  105.284500   89.982483  \n",
       "1      3.582469  0.359778  0.031265  0.830237  101.224777   95.660843  \n",
       "2      0.351208  0.359778 -0.019897  0.161896  187.626007  160.562881  \n",
       "3      0.155374  0.359778  0.007900  0.362969   79.209999   88.837372  \n",
       "4      0.253291  0.359778 -0.075191 -0.390945   55.786961   66.148277  \n",
       "...         ...       ...       ...       ...         ...         ...  \n",
       "65620  0.351208  0.359778 -0.030042  0.219719  -12.943652   10.749875  \n",
       "65621  2.505382 -2.779491 -0.146773 -1.755135  -12.985581    0.032699  \n",
       "65622  0.155374  0.359778 -0.122184  0.219719  -13.187635    0.301270  \n",
       "65623 -0.530045 -2.779491 -0.151858 -1.755135   15.672698    0.037428  \n",
       "65624 -0.432128 -2.779491 -0.169076 -1.755135    3.144708    0.024978  \n",
       "\n",
       "[65625 rows x 280 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfdf.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

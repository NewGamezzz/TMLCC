{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, SAGEConv, global_add_pool, global_mean_pool\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "MOFname                                          0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(17000, 25)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test/clean_test.csv')\n",
    "smiles = pd.read_csv('data/test/smiles_test.csv')\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e11f0e34-b17a-4f43-9a1a-0b4f0d2fc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = {\n",
    "    'atomic_num':\n",
    "    list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED',\n",
    "        'CHI_TETRAHEDRAL_CW',\n",
    "        'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER',\n",
    "    ],\n",
    "    'degree':\n",
    "    list(range(0, 11)),\n",
    "    'formal_charge':\n",
    "    list(range(-5, 7)),\n",
    "    'num_hs':\n",
    "    list(range(0, 9)),\n",
    "    'num_radical_electrons':\n",
    "    list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED',\n",
    "        'S',\n",
    "        'SP',\n",
    "        'SP2',\n",
    "        'SP3',\n",
    "        'SP3D',\n",
    "        'SP3D2',\n",
    "        'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "}\n",
    "\n",
    "e_map = {\n",
    "    'bond_type': [\n",
    "        'misc',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'AROMATIC',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "        'STEREOANY',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "c = 1\n",
    "for _, line in data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(line['Smiles'])\n",
    "    \n",
    "    if mol == None:\n",
    "        continue\n",
    "    \n",
    "    # Create Node Features\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        x.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        x.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        x.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        x.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        x.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        x.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        x.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        x.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        xs.append(x)\n",
    "    x = torch.tensor(xs, dtype=torch.float).view(-1, 9)\n",
    "    \n",
    "    # Create Edge Features\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    # Sort indices.\n",
    "    if edge_index.numel() > 0:\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    x_feat = line.drop(['MOFname', 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]', 'Smiles']).values.astype(float) #, 'weight [u]', 'functional_groups', 'CO2_working_capacity [mL/g]'\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "    y=torch.tensor([line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    data_d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=line['Smiles'], mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "    data_d.num_nodes = len(mol.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_concat.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 55125\n",
      "Number of test graphs: 10500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.16, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "data_loader = DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.conv4 = SAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f8e2a6a-ba42-4c4a-8de0-bf276fd3976b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.gine = GINE(in_xs, in_attr, dim, 128)\n",
    "        self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "        self.bn = BatchNorm1d(256)\n",
    "        self.lin = Sequential(Linear(256, 128), BatchNorm1d(128))\n",
    "        self.lin2 = Sequential(Linear(128, 128), BatchNorm1d(128))\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(128)\n",
    "        self.mlp_cross = MLP(128, 256, 128)\n",
    "        \n",
    "        self.bn_cat = BatchNorm1d(256)\n",
    "        self.mlp_cat = MLP(256, 256, 128)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(128, out_channels) # 256\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, x_feat):\n",
    "        x = self.gine(x, edge_index, edge_attr, batch)\n",
    "        x_feat = self.mlp_num(x_feat)\n",
    "        concat = torch.cat((x, x_feat),dim=1)\n",
    "        x = self.bn(concat)\n",
    "        x = self.lin(x)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "        xl = self.crossnet(x)\n",
    "        x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn_cat(x)\n",
    "        x = self.mlp_cat(x)\n",
    "        x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00365a0-505e-4adf-b703-f17774e8e674",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_attr, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.gin = GCN(in_xs, dim, 128)\n",
    "        self.mlp_num = MLP(in_xfeats, dim, 128)\n",
    "        self.bn = BatchNorm1d(256)\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(256, layer_num=2)\n",
    "        self.mlp_cross = MLP(256, 256, 256)\n",
    "        \n",
    "        self.bn_cat = BatchNorm1d(256) #64+in_xfeats\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.gin(x, edge_index, batch)\n",
    "        x_feat = self.mlp_num(x_feat)\n",
    "        concat = torch.cat((x, x_feat),dim=1)\n",
    "        x = self.bn(concat)\n",
    "        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "#         xl = self.crossnet(x)\n",
    "#         x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn_cat(hl)\n",
    "        x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a339c47-6c9b-408d-82ee-77e1efefdebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DCN, self).__init__()\n",
    "        # Deep & Cross Network\n",
    "        self.crossnet = CrossNet(in_channels)\n",
    "        self.mlp_cross = MLP(in_channels, 256, 128)\n",
    "        \n",
    "        self.bn = BatchNorm1d(128+in_channels)\n",
    "        self.mlp_cat = MLP(128+in_channels, 512, 256)\n",
    "        self.bn_out = BatchNorm1d(256)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.out = Linear(256, out_channels) # 256\n",
    "\n",
    "    def forward(self, x):        \n",
    "        # Deep & Cross Network\n",
    "        hl = self.mlp_cross(x)\n",
    "        xl = self.crossnet(x)\n",
    "        x = torch.cat((xl, hl), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.mlp_cat(x)\n",
    "        x = self.bn_out(x)\n",
    "#         x = self.dropout(x)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_xs, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.g = SAGE(in_xs, dim, 128)\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(256, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, x_feat):\n",
    "        x = self.g(x, edge_index, batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        concat = torch.cat((x, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        correct += loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 42.7481, Test MAE: 27.4539\n",
      "Epoch: 002, Train MAE: 27.0323, Test MAE: 23.3048\n",
      "Epoch: 003, Train MAE: 24.9309, Test MAE: 24.3196\n",
      "Epoch: 004, Train MAE: 24.1314, Test MAE: 25.3485\n",
      "Epoch: 005, Train MAE: 23.5789, Test MAE: 21.7817\n",
      "Epoch: 006, Train MAE: 23.1417, Test MAE: 23.2426\n",
      "Epoch: 007, Train MAE: 23.2470, Test MAE: 21.0949\n",
      "Epoch: 008, Train MAE: 22.9236, Test MAE: 21.1637\n",
      "Epoch: 009, Train MAE: 22.4238, Test MAE: 21.7181\n",
      "Epoch: 010, Train MAE: 22.2177, Test MAE: 21.4513\n",
      "Epoch: 011, Train MAE: 22.1851, Test MAE: 20.6964\n",
      "Epoch: 012, Train MAE: 22.0212, Test MAE: 21.0981\n",
      "Epoch: 013, Train MAE: 21.9116, Test MAE: 21.1088\n",
      "Epoch: 014, Train MAE: 21.5984, Test MAE: 21.5763\n",
      "Epoch: 015, Train MAE: 21.5515, Test MAE: 21.0788\n",
      "Epoch: 016, Train MAE: 21.7236, Test MAE: 20.0636\n",
      "Epoch: 017, Train MAE: 21.5306, Test MAE: 21.8361\n",
      "Epoch: 018, Train MAE: 21.5229, Test MAE: 19.9210\n",
      "Epoch: 019, Train MAE: 21.2420, Test MAE: 20.3083\n",
      "Epoch: 020, Train MAE: 21.4177, Test MAE: 19.9356\n",
      "Epoch: 021, Train MAE: 21.2270, Test MAE: 21.2711\n",
      "Epoch: 022, Train MAE: 21.0717, Test MAE: 21.5244\n",
      "Epoch: 023, Train MAE: 21.1180, Test MAE: 19.6863\n",
      "Epoch: 024, Train MAE: 21.0350, Test MAE: 20.9710\n",
      "Epoch: 025, Train MAE: 21.0218, Test MAE: 20.2974\n",
      "Epoch: 026, Train MAE: 25.5359, Test MAE: 22.2489\n",
      "Epoch: 027, Train MAE: 20.9171, Test MAE: 19.9883\n",
      "Epoch: 028, Train MAE: 20.7928, Test MAE: 20.6581\n",
      "Epoch: 029, Train MAE: 20.9014, Test MAE: 19.7277\n",
      "Epoch: 030, Train MAE: 20.7290, Test MAE: 19.5746\n",
      "Epoch: 031, Train MAE: 20.4902, Test MAE: 20.2130\n",
      "Epoch: 032, Train MAE: 20.6190, Test MAE: 19.5102\n",
      "Epoch: 033, Train MAE: 20.5298, Test MAE: 19.7815\n",
      "Epoch: 034, Train MAE: 20.4651, Test MAE: 20.3098\n",
      "Epoch: 035, Train MAE: 20.4137, Test MAE: 19.8429\n",
      "Epoch: 036, Train MAE: 20.5746, Test MAE: 20.2112\n",
      "Epoch: 037, Train MAE: 20.5300, Test MAE: 19.1733\n",
      "Epoch: 038, Train MAE: 20.3833, Test MAE: 19.6740\n",
      "Epoch: 039, Train MAE: 20.2682, Test MAE: 19.4200\n",
      "Epoch: 040, Train MAE: 20.3811, Test MAE: 19.7394\n",
      "Epoch: 041, Train MAE: 20.2231, Test MAE: 19.8272\n",
      "Epoch: 042, Train MAE: 20.3440, Test MAE: 19.5454\n",
      "Epoch: 043, Train MAE: 20.1626, Test MAE: 19.2098\n",
      "Epoch: 044, Train MAE: 20.2255, Test MAE: 19.8013\n",
      "Epoch: 045, Train MAE: 20.2570, Test MAE: 19.2959\n",
      "Epoch: 046, Train MAE: 20.0093, Test MAE: 19.5258\n",
      "Epoch: 047, Train MAE: 20.3735, Test MAE: 19.4333\n",
      "Epoch: 048, Train MAE: 20.3530, Test MAE: 19.2933\n",
      "Epoch: 049, Train MAE: 20.0226, Test MAE: 19.0451\n",
      "Epoch: 050, Train MAE: 20.0351, Test MAE: 20.3963\n",
      "Epoch: 051, Train MAE: 19.9944, Test MAE: 20.0288\n",
      "Epoch: 052, Train MAE: 20.1022, Test MAE: 19.2710\n",
      "Epoch: 053, Train MAE: 20.1277, Test MAE: 19.3589\n",
      "Epoch: 054, Train MAE: 20.0793, Test MAE: 19.2120\n",
      "Epoch: 055, Train MAE: 19.9656, Test MAE: 19.8764\n",
      "Epoch: 056, Train MAE: 19.7739, Test MAE: 19.2202\n",
      "Epoch: 057, Train MAE: 20.0276, Test MAE: 19.0484\n",
      "Epoch: 058, Train MAE: 19.7874, Test MAE: 20.7557\n",
      "Epoch: 059, Train MAE: 19.7742, Test MAE: 19.0405\n",
      "Epoch: 060, Train MAE: 19.8108, Test MAE: 19.0197\n",
      "Epoch: 061, Train MAE: 19.7830, Test MAE: 19.1911\n",
      "Epoch: 062, Train MAE: 19.8040, Test MAE: 18.9027\n",
      "Epoch: 063, Train MAE: 19.6563, Test MAE: 19.1918\n",
      "Epoch: 064, Train MAE: 19.6065, Test MAE: 18.9258\n",
      "Epoch: 065, Train MAE: 19.8253, Test MAE: 19.3290\n",
      "Epoch: 066, Train MAE: 19.7616, Test MAE: 19.2231\n",
      "Epoch: 067, Train MAE: 19.6588, Test MAE: 19.2234\n",
      "Epoch: 068, Train MAE: 19.8276, Test MAE: 19.0151\n",
      "Epoch: 069, Train MAE: 19.5878, Test MAE: 19.0649\n",
      "Epoch: 070, Train MAE: 19.7256, Test MAE: 18.8774\n",
      "Epoch: 071, Train MAE: 19.6534, Test MAE: 19.4812\n",
      "Epoch: 072, Train MAE: 19.6347, Test MAE: 19.0468\n",
      "Epoch: 073, Train MAE: 19.6359, Test MAE: 19.2263\n",
      "Epoch: 074, Train MAE: 19.6928, Test MAE: 19.9018\n",
      "Epoch: 075, Train MAE: 19.5033, Test MAE: 19.6762\n",
      "Epoch: 076, Train MAE: 19.6150, Test MAE: 19.9566\n",
      "Epoch: 077, Train MAE: 19.3727, Test MAE: 19.1295\n",
      "Epoch: 078, Train MAE: 19.5792, Test MAE: 18.9602\n",
      "Epoch: 079, Train MAE: 19.4221, Test MAE: 19.1921\n",
      "Epoch: 080, Train MAE: 19.5248, Test MAE: 19.5878\n",
      "Epoch: 081, Train MAE: 19.3833, Test MAE: 19.3593\n",
      "Epoch: 082, Train MAE: 19.4201, Test MAE: 18.9238\n",
      "Epoch: 083, Train MAE: 19.4712, Test MAE: 20.0355\n",
      "Epoch: 084, Train MAE: 19.3388, Test MAE: 19.0098\n",
      "Epoch: 085, Train MAE: 19.4723, Test MAE: 19.4111\n",
      "Epoch: 086, Train MAE: 19.4034, Test MAE: 19.0422\n",
      "Epoch: 087, Train MAE: 19.3945, Test MAE: 19.2269\n",
      "Epoch: 088, Train MAE: 19.2816, Test MAE: 19.4365\n",
      "Epoch: 089, Train MAE: 19.3904, Test MAE: 19.5951\n",
      "Epoch: 090, Train MAE: 19.2362, Test MAE: 18.8869\n",
      "Epoch: 091, Train MAE: 19.3423, Test MAE: 18.6653\n",
      "Epoch: 092, Train MAE: 19.2455, Test MAE: 19.3621\n",
      "Epoch: 093, Train MAE: 25.5404, Test MAE: 19.3160\n",
      "Epoch: 094, Train MAE: 19.7510, Test MAE: 18.9513\n",
      "Epoch: 095, Train MAE: 19.5145, Test MAE: 19.0055\n",
      "Epoch: 096, Train MAE: 19.1916, Test MAE: 18.9957\n",
      "Epoch: 097, Train MAE: 19.1307, Test MAE: 19.2428\n",
      "Epoch: 098, Train MAE: 19.2014, Test MAE: 18.9837\n",
      "Epoch: 099, Train MAE: 18.9981, Test MAE: 18.8711\n",
      "Epoch: 100, Train MAE: 19.0921, Test MAE: 18.9547\n",
      "Epoch: 101, Train MAE: 19.0807, Test MAE: 19.0384\n",
      "Epoch: 102, Train MAE: 19.2080, Test MAE: 19.7855\n",
      "Epoch: 103, Train MAE: 18.9353, Test MAE: 19.1710\n",
      "Epoch: 104, Train MAE: 19.0458, Test MAE: 19.1606\n",
      "Epoch: 105, Train MAE: 18.9867, Test MAE: 18.9123\n",
      "Epoch: 106, Train MAE: 19.0029, Test MAE: 18.7994\n",
      "Epoch: 107, Train MAE: 18.9148, Test MAE: 18.7821\n",
      "Epoch: 108, Train MAE: 19.0032, Test MAE: 19.5746\n",
      "Epoch: 109, Train MAE: 19.3837, Test MAE: 19.0245\n",
      "Epoch: 110, Train MAE: 18.9595, Test MAE: 19.3329\n",
      "Epoch: 111, Train MAE: 18.9891, Test MAE: 19.1131\n",
      "Epoch: 112, Train MAE: 19.0231, Test MAE: 18.7191\n",
      "Epoch: 113, Train MAE: 18.9477, Test MAE: 18.9565\n",
      "Epoch: 114, Train MAE: 19.0124, Test MAE: 19.1489\n",
      "Epoch: 115, Train MAE: 18.8426, Test MAE: 19.0723\n",
      "Epoch: 116, Train MAE: 18.8833, Test MAE: 19.0626\n",
      "Epoch: 117, Train MAE: 18.8373, Test MAE: 19.0372\n",
      "Epoch: 118, Train MAE: 18.8484, Test MAE: 20.2179\n",
      "Epoch: 119, Train MAE: 18.8732, Test MAE: 18.9632\n",
      "Epoch: 120, Train MAE: 18.8698, Test MAE: 19.3574\n",
      "Epoch: 121, Train MAE: 19.1524, Test MAE: 18.8761\n",
      "Epoch: 122, Train MAE: 18.9177, Test MAE: 18.9074\n",
      "Epoch: 123, Train MAE: 18.8148, Test MAE: 19.3187\n",
      "Epoch: 124, Train MAE: 18.8492, Test MAE: 19.3426\n",
      "Epoch: 125, Train MAE: 18.8321, Test MAE: 19.3177\n",
      "Epoch: 126, Train MAE: 18.8391, Test MAE: 18.8629\n",
      "Epoch: 127, Train MAE: 18.6977, Test MAE: 19.0772\n",
      "Epoch: 128, Train MAE: 18.7738, Test MAE: 19.0635\n",
      "Epoch: 129, Train MAE: 18.8681, Test MAE: 18.9798\n",
      "Epoch: 130, Train MAE: 18.8254, Test MAE: 19.3507\n",
      "Epoch: 131, Train MAE: 18.6415, Test MAE: 18.7731\n",
      "Epoch: 132, Train MAE: 18.8717, Test MAE: 19.1097\n",
      "Epoch: 133, Train MAE: 18.8430, Test MAE: 19.2930\n",
      "Epoch: 134, Train MAE: 18.5458, Test MAE: 19.1932\n",
      "Epoch: 135, Train MAE: 18.6478, Test MAE: 18.9513\n",
      "Epoch: 136, Train MAE: 18.7256, Test MAE: 19.0801\n",
      "Epoch: 137, Train MAE: 18.6700, Test MAE: 19.1041\n",
      "Epoch: 138, Train MAE: 19.2946, Test MAE: 19.2926\n",
      "Epoch: 139, Train MAE: 18.7202, Test MAE: 19.3090\n",
      "Epoch: 140, Train MAE: 18.6733, Test MAE: 19.3305\n",
      "Epoch: 141, Train MAE: 18.5899, Test MAE: 19.0038\n",
      "Epoch: 142, Train MAE: 18.5909, Test MAE: 19.5554\n",
      "Epoch: 143, Train MAE: 18.5215, Test MAE: 18.8910\n",
      "Epoch: 144, Train MAE: 18.5951, Test MAE: 18.9720\n",
      "Epoch: 145, Train MAE: 18.4796, Test MAE: 19.3885\n",
      "Epoch: 146, Train MAE: 18.4817, Test MAE: 19.1474\n",
      "Epoch: 147, Train MAE: 18.5092, Test MAE: 18.8040\n",
      "Epoch: 148, Train MAE: 18.5373, Test MAE: 19.1898\n",
      "Epoch: 149, Train MAE: 18.5099, Test MAE: 18.9566\n",
      "Epoch: 150, Train MAE: 18.3865, Test MAE: 19.3089\n",
      "Epoch: 151, Train MAE: 18.4264, Test MAE: 18.9860\n",
      "Epoch: 152, Train MAE: 18.5825, Test MAE: 19.0353\n",
      "Epoch: 153, Train MAE: 18.4837, Test MAE: 19.1150\n",
      "Epoch: 154, Train MAE: 18.4932, Test MAE: 18.9102\n",
      "Epoch: 155, Train MAE: 18.4939, Test MAE: 18.8675\n",
      "Epoch: 156, Train MAE: 18.3000, Test MAE: 19.3379\n",
      "Epoch: 157, Train MAE: 18.5155, Test MAE: 19.3523\n",
      "Epoch: 158, Train MAE: 18.3664, Test MAE: 18.9129\n",
      "Epoch: 159, Train MAE: 18.4675, Test MAE: 19.0262\n",
      "Epoch: 160, Train MAE: 18.3574, Test MAE: 19.1525\n",
      "Epoch: 161, Train MAE: 18.4031, Test MAE: 18.9191\n",
      "Epoch: 162, Train MAE: 18.2986, Test MAE: 19.1791\n",
      "Epoch: 163, Train MAE: 18.3288, Test MAE: 18.9415\n",
      "Epoch: 164, Train MAE: 18.3035, Test MAE: 18.9537\n",
      "Epoch: 165, Train MAE: 18.3122, Test MAE: 19.2508\n",
      "Epoch: 166, Train MAE: 18.3690, Test MAE: 19.4122\n",
      "Epoch: 167, Train MAE: 18.3831, Test MAE: 18.9557\n",
      "Epoch: 168, Train MAE: 18.2764, Test MAE: 19.0020\n",
      "Epoch: 169, Train MAE: 18.2680, Test MAE: 18.9499\n",
      "Epoch: 170, Train MAE: 18.2223, Test MAE: 18.9957\n",
      "Epoch: 171, Train MAE: 18.3494, Test MAE: 19.4578\n",
      "Epoch: 172, Train MAE: 18.2998, Test MAE: 19.0886\n",
      "Epoch: 173, Train MAE: 18.2664, Test MAE: 18.9179\n",
      "Epoch: 174, Train MAE: 18.1911, Test MAE: 19.3003\n",
      "Epoch: 175, Train MAE: 18.1852, Test MAE: 19.7944\n",
      "Epoch: 176, Train MAE: 18.1536, Test MAE: 19.4796\n",
      "Epoch: 177, Train MAE: 18.1857, Test MAE: 19.0073\n",
      "Epoch: 178, Train MAE: 18.2210, Test MAE: 19.2860\n",
      "Epoch: 179, Train MAE: 18.1424, Test MAE: 19.0276\n",
      "Epoch: 180, Train MAE: 18.2073, Test MAE: 19.8447\n",
      "Epoch: 181, Train MAE: 18.2208, Test MAE: 19.1945\n",
      "Epoch: 182, Train MAE: 18.1096, Test MAE: 19.1768\n",
      "Epoch: 183, Train MAE: 18.1277, Test MAE: 19.2530\n",
      "Epoch: 184, Train MAE: 18.0270, Test MAE: 19.0687\n",
      "Epoch: 185, Train MAE: 18.0110, Test MAE: 19.1170\n",
      "Epoch: 186, Train MAE: 18.0864, Test MAE: 19.0820\n",
      "Epoch: 187, Train MAE: 18.1321, Test MAE: 19.1611\n",
      "Epoch: 188, Train MAE: 18.2024, Test MAE: 19.3606\n",
      "Epoch: 189, Train MAE: 18.1324, Test MAE: 18.8709\n",
      "Epoch: 190, Train MAE: 18.1124, Test MAE: 19.9768\n",
      "Epoch: 191, Train MAE: 18.0878, Test MAE: 20.6187\n",
      "Epoch: 192, Train MAE: 18.1011, Test MAE: 18.9067\n",
      "Epoch: 193, Train MAE: 18.1709, Test MAE: 19.1569\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17732/3892759059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17732/2158525453.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Iterate in batches over the training dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Perform a single forward pass. , data.edge_attr.float()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[1;32m---> 20\u001b[1;33m                                         self.exclude_keys)\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\data\\batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0madd_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mfollow_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mexclude_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         )\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\data\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;31m# Collate attributes into a unified representation:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             value, slices, incs = _collate(attr, values, data_list, stores,\n\u001b[1;32m---> 77\u001b[1;33m                                            increment)\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mout_store\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\data\\collate.py\u001b[0m in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mincs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_dim\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_numGNN2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65625\n",
      "Number of test graphs: 16237\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19612b6d-768d-47f0-be2d-b95967d97150",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "382f0082-062f-42cb-a1b4-4b22409384eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = 9\n",
    "hidden_channels = 32\n",
    "num_feats = 21\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_node_features, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392a1c4-045e-4f56-9717-7c64816f1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out)\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>195.468613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>69.653137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>66.580437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>55.399101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>64.502907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-6.392035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.936134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>0.404633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-1.013318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-4.414718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   195.468613\n",
       "1      68615                    69.653137\n",
       "2      68616                    66.580437\n",
       "3      68617                    55.399101\n",
       "4      68618                    64.502907\n",
       "...      ...                          ...\n",
       "16995  85609                    -6.392035\n",
       "16996  85610                     1.936134\n",
       "16997  85611                     0.404633\n",
       "16998  85612                    -1.013318\n",
       "16999  85613                    -4.414718\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c6873-c420-4661-a9d2-aaf9dabfca55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

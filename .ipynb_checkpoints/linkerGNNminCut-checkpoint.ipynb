{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d8716-5267-467e-8fbf-f956bfbeeaca",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38601030-b6e2-4ea2-9844-49c943334f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINConv, GINEConv, GCNConv, GraphConv, SAGEConv, DenseSAGEConv, DenseGraphConv, ChebConv, dense_mincut_pool, global_add_pool, global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.utils import generate_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376f8b-82c5-40bb-ba48-0dedd85f7591",
   "metadata": {},
   "source": [
    "# Run Pytorch on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424459d-d858-4255-9250-1f940079f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34ea2e-7a10-4e27-8fe3-29fb7b0132a6",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649af641-29ad-4fa4-a247-173f109ad226",
   "metadata": {},
   "source": [
    "## Create Custom Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08c1f42-8508-4aac-a893-e69000ffb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOFData(Data):\n",
    "    def __init__(self, mof_node = None, mof_edge_index = None, mof_edge_attr = None,\n",
    "                        metal_node = None, metal_edge_index = None, metal_edge_attr = None,\n",
    "                        organ1_node = None, organ1_edge_index = None, organ1_edge_attr = None,\n",
    "                        organ2_node = None, organ2_edge_index = None, organ2_edge_attr = None,\n",
    "                        mofname = None, x_feat = None, y = None):\n",
    "        super().__init__()\n",
    "        self.mof_node = mof_node\n",
    "        self.mof_edge_index = mof_edge_index\n",
    "        self.mof_edge_attr = mof_edge_attr\n",
    "        \n",
    "        self.metal_node = metal_node\n",
    "        self.metal_edge_index = metal_edge_index\n",
    "        self.metal_edge_attr = metal_edge_attr\n",
    "        \n",
    "        self.organ1_node = organ1_node\n",
    "        self.organ1_edge_index = organ1_edge_index\n",
    "        self.organ1_edge_attr = organ1_edge_attr\n",
    "        \n",
    "        self.organ2_node = organ2_node\n",
    "        self.organ2_edge_index = organ2_edge_index\n",
    "        self.organ2_edge_attr = organ2_edge_attr\n",
    "        \n",
    "        self.mofname = mofname\n",
    "        self.x_feat = x_feat\n",
    "        self.y = y\n",
    "        \n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'mof_edge_index':\n",
    "            return self.mof_node.size(0)\n",
    "        if key == 'metal_edge_index':\n",
    "            return self.metal_node.size(0)\n",
    "        if key == 'organ1_edge_index':\n",
    "            return self.organ1_node.size(0)\n",
    "        if key == 'organ2_edge_index':\n",
    "            return self.organ2_node.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311ce8-9e84-4c67-8d4e-2d8f8659cbf2",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6066e87-d49c-4207-8c46-cb7983177cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOFname                                          0\n",
      "topo_0                                           0\n",
      "topo_1                                           0\n",
      "topo_2                                           0\n",
      "topo_3                                           0\n",
      "topo_4                                           0\n",
      "topo_5                                           0\n",
      "topo_6                                           0\n",
      "topo_7                                           0\n",
      "topo_8                                           0\n",
      "topo_9                                           0\n",
      "volume [A^3]                                     0\n",
      "weight [u]                                       0\n",
      "density [g/cm^3]                                 0\n",
      "surface_area [m^2/g]                             0\n",
      "void_fraction                                    0\n",
      "void_volume [cm^3/g]                             0\n",
      "functional_groups                                0\n",
      "metal_linker                                     0\n",
      "organic_linker1                                  0\n",
      "organic_linker2                                  0\n",
      "catalog CO2/N2                                   0\n",
      "CO2/N2_selectivity                               0\n",
      "heat_adsorption_CO2_P0.15bar_T298K [kcal/mol]    0\n",
      "Smiles                                           0\n",
      "dtype: int64\n",
      "(17000, 25)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test/clean_test_linker.csv')\n",
    "smiles = pd.read_csv('data/test/smiles_test.csv')\n",
    "data = df.join(smiles.set_index('MOFname'), on='MOFname')\n",
    "\n",
    "data = data.dropna(subset=['Smiles'])\n",
    "data = data.reset_index(drop=True)\n",
    "# data = data.drop('Unnamed: 0', axis=1)\n",
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc54ebf3-b60c-40b5-97cc-2d12fb058556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 10000\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_dict = []\n",
    "drop_feat = ['MOFname', 'weight [u]', 'functional_groups', 'Smiles', 'metal_linker', 'organic_linker1', 'organic_linker2'] #, 'CO2_working_capacity [mL/g]'\n",
    "c = 1\n",
    "for _, line in data.iterrows():\n",
    "    mof = Chem.MolFromSmiles(line['Smiles'])\n",
    "    metal = Chem.MolFromSmiles(line['metal_linker'])\n",
    "    organ1 = Chem.MolFromSmiles(line['organic_linker1'])\n",
    "    organ2 = Chem.MolFromSmiles(line['organic_linker2'])\n",
    "    \n",
    "    if mof == None or metal == None or organ1 == None or organ2 == None:  #or metal == None or organ1 == None or organ2 == None\n",
    "        continue\n",
    "    \n",
    "    mof_node, mof_edge_index, mof_edge_attr = generate_graph(mof)\n",
    "    metal_node, metal_edge_index, metal_edge_attr = generate_graph(metal)\n",
    "    organ1_node, organ1_edge_index, organ1_edge_attr = generate_graph(organ1)\n",
    "    organ2_node, organ2_edge_index, organ2_edge_attr = generate_graph(organ2)\n",
    "\n",
    "\n",
    "    x_feat = line.drop(drop_feat).values.astype(float)\n",
    "    x_feat = np.expand_dims(x_feat, axis=0)\n",
    "    x_feat = torch.tensor(x_feat)\n",
    "#     y=torch.tensor([line['CO2_working_capacity [mL/g]']], dtype=torch.float).view(1, -1)\n",
    "    \n",
    "    data_d = MOFData(mof_node = mof_node, mof_edge_index = mof_edge_index, mof_edge_attr = mof_edge_attr,\n",
    "                  metal_node = metal_node, metal_edge_index = metal_edge_index, metal_edge_attr = metal_edge_attr,\n",
    "                  organ1_node = organ1_node, organ1_edge_index = organ1_edge_index, organ1_edge_attr = organ1_edge_attr,\n",
    "                  organ2_node = organ2_node, organ2_edge_index = organ2_edge_index, organ2_edge_attr = organ2_edge_attr,\n",
    "                  mofname=line['MOFname'], x_feat=x_feat) #, y=y\n",
    "#     data_d.mof_num_nodes = len(mof.GetAtoms())\n",
    "    data_list.append(data_d)\n",
    "    data_dict.append(line['MOFname'])\n",
    "    \n",
    "    if(c%10000==0):\n",
    "        print('done:',c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bd46-dbbc-4b35-8136-4cbdf8b6630d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa0214f3-676a-4117-a494-237cab095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pickle.load(open('data/train/graph_concat_linker_replace_surface.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9e88aa4-e0cf-42cb-917c-f666281c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 55120\n",
      "Number of test graphs: 10500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "datasets = data_list\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(datasets, test_size=0.16, random_state = 1, shuffle=True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c803d206-82dc-46b1-a86a-3dfbb2364d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "167bf06b-c717-477f-bfcb-251a0fc2bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4fcce-2a3b-4868-94cf-9d941c63fded",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77d00-5597-4195-9fa5-96acd3649773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7735e0-f581-4bd5-97a8-ca21042e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, in_attr, dim, out_channels):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.attr1 = Sequential(Linear(in_attr, in_channels), BatchNorm1d(in_channels), ReLU())\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr2 = Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr3 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr4 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.attr5 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU())\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_attr = self.attr1(edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr2(edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr3(edge_attr)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr4(edge_attr)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        \n",
    "        edge_attr = self.attr5(edge_attr)\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b59b767-83ce-4ca5-b20a-2fd757af246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "        self.lin3 = Linear(out_channels, out_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fafd152-2a49-4276-85de-06958a565f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, dim)\n",
    "        self.conv2 = GCNConv(dim, dim)\n",
    "        self.conv3 = GCNConv(dim, dim)\n",
    "        self.conv4 = GCNConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "789f7ab1-9725-4307-86d6-c64800f952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels, num_of_centers=20):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, dim)\n",
    "        self.conv2 = SAGEConv(dim, dim)\n",
    "        self.conv3 = SAGEConv(dim, dim)\n",
    "        self.pool1 = Linear(dim, num_of_centers)\n",
    "        self.conv4 = DenseSAGEConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "#         x = self.conv3(x, edge_index).relu()\n",
    "        \n",
    "        x, mask = to_dense_batch(x, batch) \n",
    "        adj = to_dense_adj(edge_index, batch)\n",
    "        s = self.pool1(x)\n",
    "        \n",
    "        x, adj, mincut_loss, ortho_loss = dense_mincut_pool(x, adj, s, mask)\n",
    "        \n",
    "        x = self.conv4(x, adj).relu()\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin(x).relu()\n",
    "        return x, mincut_loss, ortho_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ffba7f3-45e4-495d-a44d-8c9bd2fb90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels, num_of_centers=20):\n",
    "        super(Graph, self).__init__()\n",
    "        self.conv1 = GraphConv(in_channels, dim)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.conv3 = GraphConv(dim, dim)\n",
    "        self.pool1 = Linear(dim, num_of_centers)\n",
    "        self.conv4 = DenseGraphConv(dim, dim)\n",
    "        self.lin = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "#         x = self.conv3(x, edge_index).relu()\n",
    "        \n",
    "        x, mask = to_dense_batch(x, batch) \n",
    "        adj = to_dense_adj(edge_index, batch)\n",
    "        s = self.pool1(x)\n",
    "        \n",
    "        x, adj, mincut_loss, ortho_loss = dense_mincut_pool(x, adj, s, mask)\n",
    "        \n",
    "        x = self.conv4(x, adj).relu()\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin(x).relu()\n",
    "        return x, mincut_loss, ortho_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f1cd-b88e-4662-831b-4480b173f1b4",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a9fc53d-c55d-41a4-8083-e1aabf5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(in_channels, dim)\n",
    "        self.lin2 = Linear(dim, dim)\n",
    "        self.lin3 = Linear(dim, dim)\n",
    "        self.lin4 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "#         x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a19426-45fa-4120-bc5e-e46b44a7f5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb2dbed4-82bb-45f7-9cc1-ef577c1b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))\n",
    "\n",
    "        for i in range(self.kernels.shape[0]):\n",
    "            nn.init.xavier_normal_(self.kernels[i])\n",
    "        for i in range(self.bias.shape[0]):\n",
    "            nn.init.zeros_(self.bias[i])\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82eb29-3e47-45f7-afd4-3c28c6963fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14c8bc7f-07c8-43d0-94c8-3b60f56ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_mof, in_metal, in_organ1, in_organ2, in_xfeats, dim, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.mof_g = SAGE(in_mof, dim, 128) # SAGE\n",
    "        self.metal_g = Graph(in_metal, dim, 128)\n",
    "        self.organ1_g = Graph(in_organ1, dim, 128)\n",
    "        self.organ2_g = Graph(in_organ2, dim, 128)\n",
    "        self.mlp = MLP(in_xfeats, dim, 128)\n",
    "        self.lin = Linear(256, 128)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.cross = CrossNet(128, layer_num=2)\n",
    "        self.mlp_cross = MLP(128, 128, 128)\n",
    "        self.mlp_out = MLP(256 + 128*3, 256, 256)\n",
    "        self.out = Linear(256, out_channels)\n",
    "\n",
    "    def forward(self, mof_node, mof_edge_index, mof_node_batch, \n",
    "                      metal_node, metal_edge_index, metal_node_batch,\n",
    "                      organ1_node, organ1_edge_index, organ1_node_batch,\n",
    "                      organ2_node, organ2_edge_index, organ2_node_batch, x_feat):\n",
    "        \n",
    "        mof, mof_mincut_loss, mof_ortho_loss = self.mof_g(mof_node, mof_edge_index, mof_node_batch)\n",
    "        metal, metal_mincut_loss, metal_ortho_loss = self.metal_g(metal_node, metal_edge_index, metal_node_batch)\n",
    "        organ1, organ1_mincut_loss, organ1_ortho_loss = self.organ1_g(organ1_node, organ1_edge_index, organ1_node_batch)\n",
    "        organ2, organ2_mincut_loss, organ2_ortho_loss = self.organ2_g(organ2_node, organ2_edge_index, organ2_node_batch)\n",
    "        x_feat = self.mlp(x_feat)\n",
    "        \n",
    "        concat = torch.cat((mof, x_feat), dim=1)\n",
    "        x = self.lin(concat)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        x = self.lin2(x).relu()\n",
    "        \n",
    "        cross = self.cross(x)\n",
    "        mlp_cross = self.mlp_cross(x)\n",
    "        concat2 = torch.cat((cross, mlp_cross, metal, organ1, organ2), dim=1)\n",
    "        \n",
    "        x = self.mlp_out(concat2)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # SAGE: 0.3\n",
    "        out = self.out(x)\n",
    "        return out, mof_mincut_loss + mof_ortho_loss + metal_mincut_loss + metal_ortho_loss + organ1_mincut_loss + organ1_ortho_loss + organ2_mincut_loss + organ2_ortho_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436d70d-f407-4829-bc1a-70ff24aef54d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "711f76cb-8705-4ebf-a0ce-2b21ac50f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    c=0\n",
    "    correct=0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out, pool_loss = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float())  # Perform a single forward pass. , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y) + pool_loss  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        c=c+1\n",
    "        correct+=loss.cpu().detach().numpy() - pool_loss.cpu().detach().numpy()\n",
    "    return correct/c\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    c=0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out, pool_loss = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float()) # , data.edge_attr.float()\n",
    "    \n",
    "        loss = criterion(out, data.y) + pool_loss  # Compute the loss.\n",
    "        correct+=loss.cpu().detach().numpy() - pool_loss.cpu().detach().numpy()  # Check against ground-truth labels.\n",
    "        c=c+1\n",
    "    return correct / c  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08571f39-3903-4f7a-8fa8-769e373c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mof_node = 9\n",
    "num_metal_node = 9\n",
    "num_organ1_node = 9\n",
    "num_organ2_node = 9\n",
    "hidden_channels = 32 # SAGE: 32\n",
    "num_feats = 18\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_mof_node, num_metal_node, num_organ1_node, num_organ2_node, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001) #factor=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbf307aa-531c-49ac-87f3-b48da24513e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Epoch: 001, Train MAE: 37.4608, Test MAE: 26.2974\n",
      "Epoch: 002, Train MAE: 26.1060, Test MAE: 23.2140\n",
      "Epoch: 003, Train MAE: 24.2635, Test MAE: 23.3522\n",
      "Epoch: 004, Train MAE: 23.2698, Test MAE: 23.6859\n",
      "Epoch: 005, Train MAE: 22.9477, Test MAE: 21.3307\n",
      "Epoch: 006, Train MAE: 22.8410, Test MAE: 21.1939\n",
      "Epoch: 007, Train MAE: 22.1977, Test MAE: 21.6888\n",
      "Epoch: 008, Train MAE: 22.2351, Test MAE: 20.8897\n",
      "Epoch: 009, Train MAE: 22.3834, Test MAE: 20.6114\n",
      "Epoch: 010, Train MAE: 22.4387, Test MAE: 22.1569\n",
      "Epoch: 011, Train MAE: 22.0160, Test MAE: 20.6636\n",
      "Epoch: 012, Train MAE: 21.8224, Test MAE: 21.7065\n",
      "Epoch: 013, Train MAE: 21.7253, Test MAE: 20.1260\n",
      "Epoch: 014, Train MAE: 21.6161, Test MAE: 19.9027\n",
      "Epoch: 015, Train MAE: 21.1808, Test MAE: 20.4244\n",
      "Epoch: 016, Train MAE: 21.2526, Test MAE: 22.8809\n",
      "Epoch: 017, Train MAE: 21.4786, Test MAE: 19.9083\n",
      "Epoch: 018, Train MAE: 20.9490, Test MAE: 20.0091\n",
      "Epoch: 019, Train MAE: 20.8059, Test MAE: 20.5903\n",
      "Epoch: 020, Train MAE: 20.8070, Test MAE: 19.5984\n",
      "Epoch: 021, Train MAE: 20.8229, Test MAE: 20.2886\n",
      "Epoch: 022, Train MAE: 20.7342, Test MAE: 19.9071\n",
      "Epoch: 023, Train MAE: 20.6841, Test MAE: 19.7606\n",
      "Epoch: 024, Train MAE: 20.6523, Test MAE: 19.5395\n",
      "Epoch: 025, Train MAE: 20.4608, Test MAE: 19.3265\n",
      "Epoch: 026, Train MAE: 20.5951, Test MAE: 19.7769\n",
      "Epoch: 027, Train MAE: 20.5324, Test MAE: 19.7410\n",
      "Epoch: 028, Train MAE: 20.3436, Test MAE: 19.5438\n",
      "Epoch: 029, Train MAE: 20.3959, Test MAE: 20.1763\n",
      "Epoch: 030, Train MAE: 20.2768, Test MAE: 19.6808\n",
      "Epoch: 031, Train MAE: 20.1646, Test MAE: 19.1923\n",
      "Epoch: 032, Train MAE: 20.0546, Test MAE: 19.0093\n",
      "Epoch: 033, Train MAE: 20.1016, Test MAE: 19.2737\n",
      "Epoch: 034, Train MAE: 20.0913, Test MAE: 19.5408\n",
      "Epoch: 035, Train MAE: 20.0151, Test MAE: 19.4896\n",
      "Epoch: 036, Train MAE: 20.0089, Test MAE: 19.5478\n",
      "Epoch: 037, Train MAE: 19.8665, Test MAE: 18.9874\n",
      "Epoch: 038, Train MAE: 19.8528, Test MAE: 22.9091\n",
      "Epoch: 039, Train MAE: 19.9320, Test MAE: 19.5477\n",
      "Epoch: 040, Train MAE: 19.6913, Test MAE: 19.0528\n",
      "Epoch: 041, Train MAE: 19.8130, Test MAE: 19.1189\n",
      "Epoch: 042, Train MAE: 19.6301, Test MAE: 19.4852\n",
      "Epoch: 043, Train MAE: 19.5072, Test MAE: 18.9661\n",
      "Epoch: 044, Train MAE: 19.5297, Test MAE: 18.8953\n",
      "Epoch: 045, Train MAE: 19.5126, Test MAE: 18.7785\n",
      "Epoch: 046, Train MAE: 19.3837, Test MAE: 18.8277\n",
      "Epoch: 047, Train MAE: 19.3960, Test MAE: 19.4753\n",
      "Epoch: 048, Train MAE: 19.3784, Test MAE: 19.2890\n",
      "Epoch: 049, Train MAE: 19.3336, Test MAE: 18.8967\n",
      "Epoch: 050, Train MAE: 19.3029, Test MAE: 19.0745\n",
      "Epoch: 051, Train MAE: 19.3216, Test MAE: 18.9478\n",
      "Epoch: 052, Train MAE: 19.1720, Test MAE: 19.1608\n",
      "Epoch: 053, Train MAE: 19.2647, Test MAE: 18.7329\n",
      "Epoch: 054, Train MAE: 19.1601, Test MAE: 18.8916\n",
      "Epoch: 055, Train MAE: 19.1872, Test MAE: 19.4602\n",
      "Epoch: 056, Train MAE: 19.2140, Test MAE: 19.0177\n",
      "Epoch: 057, Train MAE: 18.9637, Test MAE: 18.9195\n",
      "Epoch: 058, Train MAE: 19.0673, Test MAE: 19.4122\n",
      "Epoch: 059, Train MAE: 18.9917, Test MAE: 18.7278\n",
      "Epoch: 060, Train MAE: 18.9378, Test MAE: 18.6516\n",
      "Epoch: 061, Train MAE: 18.8945, Test MAE: 18.6903\n",
      "Epoch: 062, Train MAE: 18.9072, Test MAE: 18.6782\n",
      "Epoch: 063, Train MAE: 18.8607, Test MAE: 18.9498\n",
      "Epoch: 064, Train MAE: 18.9059, Test MAE: 18.9658\n",
      "Epoch: 065, Train MAE: 18.7977, Test MAE: 18.6301\n",
      "Epoch: 066, Train MAE: 18.7129, Test MAE: 18.7014\n",
      "Epoch: 067, Train MAE: 18.7709, Test MAE: 18.9003\n",
      "Epoch: 068, Train MAE: 18.7231, Test MAE: 18.8243\n",
      "Epoch: 069, Train MAE: 18.7968, Test MAE: 18.6340\n",
      "Epoch: 070, Train MAE: 18.6257, Test MAE: 18.5625\n",
      "Epoch: 071, Train MAE: 18.5517, Test MAE: 18.5785\n",
      "Epoch: 072, Train MAE: 18.5560, Test MAE: 18.6569\n",
      "Epoch: 073, Train MAE: 18.5635, Test MAE: 18.5260\n",
      "Epoch: 074, Train MAE: 18.5574, Test MAE: 18.4931\n",
      "Epoch: 075, Train MAE: 18.5675, Test MAE: 18.6200\n",
      "Epoch: 076, Train MAE: 18.5223, Test MAE: 18.6801\n",
      "Epoch: 077, Train MAE: 18.4499, Test MAE: 18.7138\n",
      "Epoch: 078, Train MAE: 18.4929, Test MAE: 18.6603\n",
      "Epoch: 079, Train MAE: 18.3696, Test MAE: 18.6406\n",
      "Epoch: 080, Train MAE: 18.4012, Test MAE: 18.5021\n",
      "Epoch: 081, Train MAE: 18.3927, Test MAE: 18.5018\n",
      "Epoch: 082, Train MAE: 18.4206, Test MAE: 18.5810\n",
      "Epoch: 083, Train MAE: 18.3632, Test MAE: 18.5226\n",
      "Epoch: 084, Train MAE: 18.2787, Test MAE: 18.5146\n",
      "Epoch: 085, Train MAE: 18.2564, Test MAE: 18.5226\n",
      "Epoch: 086, Train MAE: 18.2648, Test MAE: 18.5446\n",
      "Epoch: 087, Train MAE: 18.2222, Test MAE: 18.5044\n",
      "Epoch: 088, Train MAE: 18.1695, Test MAE: 18.7889\n",
      "Epoch: 089, Train MAE: 18.1559, Test MAE: 18.5346\n",
      "Epoch: 090, Train MAE: 18.1107, Test MAE: 18.5370\n",
      "Epoch: 091, Train MAE: 18.1229, Test MAE: 18.4624\n",
      "Epoch: 092, Train MAE: 18.0922, Test MAE: 18.4380\n",
      "Epoch: 093, Train MAE: 18.0590, Test MAE: 18.5718\n",
      "Epoch: 094, Train MAE: 18.1192, Test MAE: 18.4910\n",
      "Epoch: 095, Train MAE: 18.1092, Test MAE: 18.5594\n",
      "Epoch: 096, Train MAE: 18.1261, Test MAE: 18.6762\n",
      "Epoch: 097, Train MAE: 17.9921, Test MAE: 18.4631\n",
      "Epoch: 098, Train MAE: 18.0222, Test MAE: 18.4827\n",
      "Epoch: 099, Train MAE: 17.9459, Test MAE: 18.5545\n",
      "Epoch: 100, Train MAE: 17.9747, Test MAE: 18.4762\n",
      "Epoch: 101, Train MAE: 17.9512, Test MAE: 18.4687\n",
      "Epoch: 102, Train MAE: 17.9398, Test MAE: 18.3954\n",
      "Epoch: 103, Train MAE: 17.8799, Test MAE: 18.5786\n",
      "Epoch: 104, Train MAE: 17.8811, Test MAE: 18.7373\n",
      "Epoch: 105, Train MAE: 17.9155, Test MAE: 18.6739\n",
      "Epoch: 106, Train MAE: 17.9179, Test MAE: 18.5136\n",
      "Epoch: 107, Train MAE: 17.8554, Test MAE: 18.4481\n",
      "Epoch: 108, Train MAE: 17.8630, Test MAE: 18.4261\n",
      "Epoch: 109, Train MAE: 17.8231, Test MAE: 18.5247\n",
      "Epoch: 110, Train MAE: 17.8279, Test MAE: 18.5645\n",
      "Epoch: 111, Train MAE: 17.8442, Test MAE: 18.4625\n",
      "Epoch: 112, Train MAE: 17.7980, Test MAE: 18.5062\n",
      "Epoch: 113, Train MAE: 17.7860, Test MAE: 18.4340\n",
      "Epoch: 114, Train MAE: 17.8235, Test MAE: 18.4435\n",
      "Epoch: 115, Train MAE: 17.7324, Test MAE: 18.4771\n",
      "Epoch: 116, Train MAE: 17.6633, Test MAE: 18.4564\n",
      "Epoch: 117, Train MAE: 17.7601, Test MAE: 18.4674\n",
      "Epoch: 118, Train MAE: 17.6945, Test MAE: 18.4366\n",
      "Epoch: 119, Train MAE: 17.6649, Test MAE: 18.4347\n",
      "Epoch: 120, Train MAE: 17.6983, Test MAE: 18.4927\n",
      "Epoch: 121, Train MAE: 17.6748, Test MAE: 18.4625\n",
      "Epoch: 122, Train MAE: 17.7588, Test MAE: 18.4250\n",
      "Epoch: 123, Train MAE: 17.6710, Test MAE: 18.4675\n",
      "Epoch: 124, Train MAE: 17.6370, Test MAE: 18.4776\n",
      "Epoch: 125, Train MAE: 17.6327, Test MAE: 18.4771\n",
      "Epoch: 126, Train MAE: 17.6360, Test MAE: 18.4435\n",
      "Epoch: 127, Train MAE: 17.5903, Test MAE: 18.4590\n",
      "Epoch: 128, Train MAE: 17.6071, Test MAE: 18.4791\n",
      "Epoch: 129, Train MAE: 17.5659, Test MAE: 18.4325\n",
      "Epoch: 130, Train MAE: 17.6496, Test MAE: 18.4666\n",
      "Epoch: 131, Train MAE: 17.5947, Test MAE: 18.4786\n",
      "Epoch: 132, Train MAE: 17.6157, Test MAE: 18.4669\n",
      "Epoch: 133, Train MAE: 17.6627, Test MAE: 18.4774\n",
      "Epoch: 134, Train MAE: 17.5699, Test MAE: 18.4932\n",
      "Epoch: 135, Train MAE: 17.5584, Test MAE: 18.4785\n",
      "Epoch: 136, Train MAE: 17.5949, Test MAE: 18.4515\n",
      "Epoch: 137, Train MAE: 17.5494, Test MAE: 18.4670\n",
      "Epoch: 138, Train MAE: 17.6120, Test MAE: 18.4916\n",
      "Epoch: 139, Train MAE: 17.5722, Test MAE: 18.4628\n",
      "Epoch: 140, Train MAE: 17.5951, Test MAE: 18.4653\n",
      "Epoch: 141, Train MAE: 17.5587, Test MAE: 18.4506\n",
      "Epoch: 142, Train MAE: 17.5081, Test MAE: 18.4507\n",
      "Epoch: 143, Train MAE: 17.6121, Test MAE: 18.4709\n",
      "Epoch: 144, Train MAE: 17.5252, Test MAE: 18.4804\n",
      "Epoch: 145, Train MAE: 17.5152, Test MAE: 18.4717\n",
      "Epoch: 146, Train MAE: 17.5569, Test MAE: 18.4829\n",
      "Epoch: 147, Train MAE: 17.4719, Test MAE: 18.4582\n",
      "Epoch: 148, Train MAE: 17.5319, Test MAE: 18.4840\n",
      "Epoch: 149, Train MAE: 17.5683, Test MAE: 18.4704\n",
      "Epoch: 150, Train MAE: 17.5006, Test MAE: 18.4687\n",
      "Epoch: 151, Train MAE: 17.4877, Test MAE: 18.4722\n",
      "Epoch: 152, Train MAE: 17.4987, Test MAE: 18.4556\n",
      "Epoch: 153, Train MAE: 17.4963, Test MAE: 18.4688\n",
      "Epoch: 154, Train MAE: 17.5070, Test MAE: 18.4642\n",
      "Epoch: 155, Train MAE: 17.4813, Test MAE: 18.4821\n",
      "Epoch: 156, Train MAE: 17.5314, Test MAE: 18.4780\n",
      "Epoch: 157, Train MAE: 17.5238, Test MAE: 18.4765\n",
      "Epoch: 158, Train MAE: 17.5085, Test MAE: 18.4471\n",
      "Epoch: 159, Train MAE: 17.4870, Test MAE: 18.4990\n",
      "Epoch: 160, Train MAE: 17.4795, Test MAE: 18.4717\n",
      "Epoch: 161, Train MAE: 17.5204, Test MAE: 18.4591\n",
      "Epoch: 162, Train MAE: 17.5238, Test MAE: 18.4682\n",
      "Epoch: 163, Train MAE: 17.5374, Test MAE: 18.4819\n",
      "Epoch: 164, Train MAE: 17.4981, Test MAE: 18.4718\n",
      "Epoch: 165, Train MAE: 17.4715, Test MAE: 18.4735\n",
      "Epoch: 166, Train MAE: 17.5278, Test MAE: 18.4931\n",
      "Epoch: 167, Train MAE: 17.4310, Test MAE: 18.4643\n",
      "Epoch: 168, Train MAE: 17.4312, Test MAE: 18.4621\n",
      "Epoch: 169, Train MAE: 17.5244, Test MAE: 18.4611\n",
      "Epoch: 170, Train MAE: 17.4073, Test MAE: 18.4695\n",
      "Epoch: 171, Train MAE: 17.4992, Test MAE: 18.4671\n",
      "Epoch: 172, Train MAE: 17.4818, Test MAE: 18.4775\n",
      "Epoch: 173, Train MAE: 17.4384, Test MAE: 18.4649\n",
      "Epoch: 174, Train MAE: 17.5255, Test MAE: 18.4623\n",
      "Epoch: 175, Train MAE: 17.4637, Test MAE: 18.4788\n",
      "Epoch: 176, Train MAE: 17.5232, Test MAE: 18.4727\n",
      "Epoch: 177, Train MAE: 17.4644, Test MAE: 18.4689\n",
      "Epoch: 178, Train MAE: 17.4227, Test MAE: 18.4699\n",
      "Epoch: 179, Train MAE: 17.4524, Test MAE: 18.4633\n",
      "Epoch: 180, Train MAE: 17.4406, Test MAE: 18.4693\n",
      "Epoch: 181, Train MAE: 17.4821, Test MAE: 18.4671\n",
      "Epoch: 182, Train MAE: 17.4322, Test MAE: 18.4760\n",
      "Epoch: 183, Train MAE: 17.4388, Test MAE: 18.4637\n",
      "Epoch: 184, Train MAE: 17.4712, Test MAE: 18.4715\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "print('start train')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_loss.append(train_acc)\n",
    "    test_loss.append(test_acc)\n",
    "    scheduler.step(test_acc)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train MAE: {train_acc:.4f}, Test MAE: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35131580-625c-463b-ae2d-9d78aec742df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(epochs), train_loss, label='train loss')\n",
    "plt.plot(np.arange(epochs), test_loss, label='val loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b497b990-bad4-4a60-a567-4fb855089f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(model.state_dict(), \"model/best_linkerGNNminCut.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24b96-0bb4-4825-8511-025d23c07178",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b58b-befe-46af-9ac2-cb889717fceb",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e876ea1-3a3e-4f5d-bfa6-420b19b1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 65620\n",
      "Number of test graphs: 16235\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('data/train/graph_concat_linker_replace_surface.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('data/test/graph_concat_linker.pkl', 'rb'))\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b15ad756-929a-4341-a850-2443109b32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = []\n",
    "test_feat = []\n",
    "\n",
    "for train_data in train_dataset:\n",
    "    train_feat.append(train_data.x_feat)\n",
    "    \n",
    "for test_data in test_dataset:\n",
    "    test_feat.append(test_data.x_feat)\n",
    "\n",
    "\n",
    "train_feat = torch.cat(train_feat, axis=0)\n",
    "test_feat = torch.cat(test_feat, axis=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_feat = torch.from_numpy(sc.fit_transform(train_feat))\n",
    "test_feat = torch.from_numpy(sc.transform(test_feat))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data.x_feat = train_feat[i].unsqueeze(0)\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    data.x_feat = test_feat[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8c5717e-5674-4121-966a-c3babae5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, follow_batch=['mof_node', 'metal_node', 'organ1_node', 'organ2_node'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2ece4-05e7-469a-a880-0eb27fe99531",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "160f8d28-db63-4202-ab0f-64e030d9b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (mof_g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (metal_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ1_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ2_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=18, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=640, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_mof_node = 9\n",
    "num_metal_node = 9\n",
    "num_organ1_node = 9\n",
    "num_organ2_node = 9\n",
    "hidden_channels = 32 # SAGE: 32\n",
    "num_feats = 18\n",
    "num_classes = 1\n",
    "num_attr = 3\n",
    "\n",
    "model = Net(num_mof_node, num_metal_node, num_organ1_node, num_organ2_node, num_feats, hidden_channels, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.001\n",
    "criterion = torch.nn.L1Loss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.85, patience=3, min_lr=0.000001) #factor=0.85\n",
    "\n",
    "model.load_state_dict(torch.load('model/best_linkerGNNminCut.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3c94-3bb9-44c0-acc4-8e582aeac2d3",
   "metadata": {},
   "source": [
    "## Evaluate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35b0b9ff-5788-47ec-a798-27ac83cac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mofname = []\n",
    "co2_select = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    \n",
    "    out, pool_loss = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                            data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                            data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                            data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float())\n",
    "    \n",
    "    mofname.append(data.mofname)\n",
    "    co2_select.append(out.cpu().detach().numpy())\n",
    "    \n",
    "mofname = np.concatenate(mofname)\n",
    "co2_select = np.concatenate(co2_select).flatten()\n",
    "\n",
    "cut_mof_unit = lambda x: x.split('_')[-1]\n",
    "id_ = np.array(list(map(cut_mof_unit, mofname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9db2345b-cf9e-43c3-bc68-67993c405a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': id_, 'CO2_working_capacity [mL/g]': co2_select}\n",
    "\n",
    "df_inference = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7435fc60-3757-427b-a8c1-bffe25e4fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost = pd.read_csv('xgboost_submission.csv')\n",
    "df_xgboost = df_xgboost.set_index('id')\n",
    "\n",
    "df_xgboost.loc[df_inference.id.values.astype(int)] = np.expand_dims(df_inference['CO2_working_capacity [mL/g]'].values, axis=1)\n",
    "df_xgboost = df_xgboost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efb0471b-287b-4ffa-b888-f363e344f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgboost.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fb8d3ae-2411-4ea2-856f-fe7cd2c5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CO2_working_capacity [mL/g]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68614</td>\n",
       "      <td>192.599228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68615</td>\n",
       "      <td>66.363136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68616</td>\n",
       "      <td>67.216171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68617</td>\n",
       "      <td>55.901829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68618</td>\n",
       "      <td>64.024391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>85609</td>\n",
       "      <td>-5.661958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>85610</td>\n",
       "      <td>1.520870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>85611</td>\n",
       "      <td>-0.013260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>85612</td>\n",
       "      <td>-0.944833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>85613</td>\n",
       "      <td>-3.797317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CO2_working_capacity [mL/g]\n",
       "0      68614                   192.599228\n",
       "1      68615                    66.363136\n",
       "2      68616                    67.216171\n",
       "3      68617                    55.901829\n",
       "4      68618                    64.024391\n",
       "...      ...                          ...\n",
       "16995  85609                    -5.661958\n",
       "16996  85610                     1.520870\n",
       "16997  85611                    -0.013260\n",
       "16998  85612                    -0.944833\n",
       "16999  85613                    -3.797317\n",
       "\n",
       "[17000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfd22f-5ebe-43cd-9621-06a0ddcd6f37",
   "metadata": {},
   "source": [
    "## Create Latent Space for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3da5e7a7-88cc-46b5-a7e5-2aca58e7215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (mof_g): SAGE(\n",
       "    (conv1): SAGEConv(9, 32)\n",
       "    (conv2): SAGEConv(32, 32)\n",
       "    (conv3): SAGEConv(32, 32)\n",
       "    (conv4): SAGEConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (metal_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ1_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (organ2_g): Graph(\n",
       "    (conv1): GraphConv(9, 32)\n",
       "    (conv2): GraphConv(32, 32)\n",
       "    (conv3): GraphConv(32, 32)\n",
       "    (conv4): GraphConv(32, 32)\n",
       "    (lin): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (lin1): Linear(in_features=18, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (lin4): Linear(in_features=32, out_features=128, bias=True)\n",
       "  )\n",
       "  (lin): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cross): CrossNet()\n",
       "  (mlp_cross): MLP(\n",
       "    (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (lin4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp_out): MLP(\n",
       "    (lin1): Linear(in_features=640, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out=nn.Sequential(*list(model.out.children())[:-1])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "91628a15-bd6f-4df6-812e-d86634bc8e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n",
      "done: 200\n",
      "done: 300\n",
      "done: 400\n",
      "done: 500\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "train_x = []\n",
    "train_y = []\n",
    "train_mofname = []\n",
    "\n",
    "for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    train_x.append(out)\n",
    "    train_y.append(data.y.cpu().detach().numpy())\n",
    "    train_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "train_x = np.concatenate(train_x, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "train_mofname = np.concatenate(train_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "00dc8e64-9c19-401b-864d-13b4539fa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\TMLCC_CUDA\\lib\\site-packages\\torch_geometric\\data\\storage.py:249: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'organ2_edge_index', 'mof_edge_index', 'x_feat', 'metal_edge_index', 'organ1_edge_index', 'metal_edge_attr', 'organ2_node', 'mofname', 'organ2_edge_attr', 'organ1_node', 'organ1_edge_attr', 'metal_node', 'mof_edge_attr', 'mof_node'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  \" to suppress this warning\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 100\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "test_x = []\n",
    "test_mofname = []\n",
    "\n",
    "for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "    data.to(device)\n",
    "    out = model(data.mof_node, data.mof_edge_index, data.mof_node_batch,\n",
    "                data.metal_node, data.metal_edge_index, data.metal_node_batch,\n",
    "                data.organ1_node, data.organ1_edge_index, data.organ1_node_batch,\n",
    "                data.organ2_node, data.organ2_edge_index, data.organ2_node_batch, data.x_feat.float()).cpu().detach().numpy()\n",
    "    x_feat = data.x_feat.cpu().detach().numpy()\n",
    "\n",
    "    out = np.concatenate((out, x_feat), axis=1)\n",
    "    test_x.append(out)\n",
    "    test_mofname.append(data.mofname)\n",
    "    c=c+1\n",
    "    if(c%100==0):\n",
    "        print('done:',c)\n",
    "\n",
    "test_x = np.concatenate(test_x, axis=0)\n",
    "test_mofname = np.concatenate(test_mofname, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a8b951cd-46fd-4d9a-b530-cdf6e6cfc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_x)\n",
    "test_df = pd.DataFrame(test_x)\n",
    "\n",
    "train_df['target'] = train_y.flatten()\n",
    "test_df['mofname'] = test_mofname.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9c59a166-f0e8-438e-95fb-49c5fa3af489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train/Latent_SAGEGNN_feat_linker_train.csv',index=False)\n",
    "test_df.to_csv('data/test/auto_SAGEGNN_feat_linker_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12171eea-b02a-49f7-b95d-493d132fec69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLCC_CUDA",
   "language": "python",
   "name": "tmlcc_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
